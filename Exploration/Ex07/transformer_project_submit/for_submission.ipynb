{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d60a3ffa",
      "metadata": {
        "id": "d60a3ffa"
      },
      "source": [
        "## Step 1: Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "id": "lhCCPcWRKUU6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhCCPcWRKUU6",
        "outputId": "3f22f065-75cb-407c-aeda-9bf99b14e64e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: mps\n"
          ]
        }
      ],
      "source": [
        "# ===== 필요한 라이브러리 import =====\n",
        "\n",
        "# PyTorch 관련\n",
        "import torch  # PyTorch 메인 라이브러리\n",
        "import torch.nn as nn  # 신경망 모듈 (레이어, 활성화 함수 등)\n",
        "import torch.optim as optim  # 최적화 알고리즘 (Adam, SGD 등)\n",
        "import torch.nn.functional as F  # 함수형 API (softmax, relu 등)\n",
        "\n",
        "# 데이터 처리 관련\n",
        "import pandas as pd  # 데이터프레임 처리 (CSV 읽기 등)\n",
        "import numpy as np  # 수치 연산\n",
        "import re  # 정규표현식 (텍스트 전처리)\n",
        "import math  # 수학 함수 (sin, cos 등)\n",
        "\n",
        "# 토크나이저 및 데이터 로더\n",
        "import sentencepiece as spm  # SentencePiece 토크나이저 (서브워드 단위)\n",
        "from sklearn.model_selection import train_test_split  # 데이터를 train/val/test로 분할\n",
        "from torch.utils.data import Dataset, DataLoader  # PyTorch 데이터셋 및 배치 로더\n",
        "\n",
        "# 유틸리티\n",
        "from tqdm import tqdm  # 진행바 표시용\n",
        "import easydict  # 딕셔너리를 객체처럼 사용 가능 (config.emb_dim 형태)\n",
        "\n",
        "# 디바이스 설정: Apple Silicon의 MPS 가속기 사용 가능하면 사용, 아니면 CPU\n",
        "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')  # 현재 사용 중인 디바이스 출력\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82c7115a",
      "metadata": {
        "id": "82c7115a"
      },
      "source": [
        "## Step 2: Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 243,
      "id": "ddHSeE00KUU8",
      "metadata": {
        "id": "ddHSeE00KUU8"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sentence):\n",
        "    \"\"\"\n",
        "    단일 문장을 전처리하는 함수\n",
        "    목적: 텍스트 데이터를 정제하여 모델 학습에 적합한 형태로 만듦\n",
        "    \"\"\"\n",
        "    # 입력 검증: 비어있거나 None인 경우 빈 문자열 반환\n",
        "    if pd.isna(sentence) or sentence is None:\n",
        "        return \"\"\n",
        "\n",
        "    # 문자열로 변환 (안전장치)\n",
        "    sentence = str(sentence)\n",
        "\n",
        "    # 정규표현식으로 필요한 문자만 남기기\n",
        "    # ㄱ-ㅎ: 자음, ㅏ-ㅣ: 모음, 가-힣: 완성형 한글\n",
        "    # a-zA-Z: 영어, 0-9: 숫자, \\s: 공백\n",
        "    # .,!?~: 문장부호, ㅠㅜ: 이모티콘\n",
        "    # 나머지는 모두 공백으로 치환\n",
        "    sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9\\s.,!?~ㅠㅜ]', ' ', sentence) #re.sub는 정규표현식(regex)을 사용하여 특정 패턴의 문자를 찾아 다른 문자로 바꿉니다.\n",
        "\n",
        "    # 연속된 여러 공백을 하나의 공백으로 통일\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    # 설명: \\s는 공백, +는 \"1개 이상\"을 의미합니다. 즉, \\s+는 \"1개 이상의 연속된 공백\"(예: \" \", \" \", \" \")을 찾습니다.\n",
        "\n",
        "    # 동작: 이렇게 찾은 연속된 공백 뭉치를 **하나의 공백(' ')**으로 압축합니다.\n",
        "\n",
        "    # 이유: 바로 앞 단계에서 Hi!!^^가 Hi 처럼 여러 공백으로 바뀔 수 있습니다. 단어 사이처럼 불필요하게 공백이 많은 것은 단어 사이와 동일하게 취급되어야 합니다.\n",
        "\n",
        "    # 문장 앞뒤 공백 제거\n",
        "    sentence = sentence.strip()\n",
        "\n",
        "    # 연속된 문장부호 정리 (예: !!! -> !, ??? -> ?)\n",
        "    # ([!?.])를 캡처하고 \\1+로 반복을 찾아서 r'\\1'로 하나만 남김\n",
        "    sentence = re.sub(r'([!?.])\\1+', r'\\1', sentence)\n",
        "\n",
        "    return sentence\n",
        "\n",
        "\n",
        "def load_and_preprocess_data(file_path):\n",
        "    \"\"\"\n",
        "    CSV 파일에서 질문-답변 데이터를 로드하고 전처리\n",
        "    \"\"\"\n",
        "    print(\"=\" * 50)\n",
        "    print(\"데이터 로드 및 전처리 중...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # pandas로 CSV 파일 읽기\n",
        "    df = pd.read_csv(file_path)\n",
        "    print(f\"전체 데이터: {len(df)} 쌍\")\n",
        "\n",
        "    # 전처리된 질문과 답변을 저장할 리스트 초기화\n",
        "    questions = []\n",
        "    answers = []\n",
        "\n",
        "    # 모든 질문-답변 쌍을 순회\n",
        "    for i, (q, a) in enumerate(zip(df['Q'], df['A'])):\n",
        "        # 각각 전처리 적용\n",
        "        clean_q = preprocess_sentence(q)\n",
        "        clean_a = preprocess_sentence(a)\n",
        "\n",
        "        # 둘 다 유효한 문장인 경우만 저장\n",
        "        if clean_q and clean_a:\n",
        "            questions.append(clean_q)\n",
        "            answers.append(clean_a)\n",
        "\n",
        "        # 진행 상황 출력 (매 1000개마다)\n",
        "        if (i + 1) % 1000 == 0:\n",
        "            print(f\"진행: {i + 1}/{len(df)}\")\n",
        "\n",
        "    print(f\"\\n전처리 후 유효한 쌍: {len(questions)}\")\n",
        "    print(\"\\n샘플 데이터:\")\n",
        "\n",
        "    # 처음 3개의 샘플 데이터 출력하여 확인\n",
        "    for i in range(min(3, len(questions))):\n",
        "        print(f\"Q: {questions[i]}\")\n",
        "        print(f\"A: {answers[i]}\\n\")\n",
        "\n",
        "    return questions, answers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 244,
      "id": "T_yMit4sKUU8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_yMit4sKUU8",
        "outputId": "ae95833a-e0f9-4ff5-9d60-2b6079c5e282"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "데이터 로드 및 전처리 중...\n",
            "==================================================\n",
            "전체 데이터: 11823 쌍\n",
            "진행: 1000/11823\n",
            "진행: 2000/11823\n",
            "진행: 3000/11823\n",
            "진행: 4000/11823\n",
            "진행: 5000/11823\n",
            "진행: 6000/11823\n",
            "진행: 7000/11823\n",
            "진행: 8000/11823\n",
            "진행: 9000/11823\n",
            "진행: 10000/11823\n",
            "진행: 11000/11823\n",
            "\n",
            "전처리 후 유효한 쌍: 11823\n",
            "\n",
            "샘플 데이터:\n",
            "Q: 12시 땡!\n",
            "A: 하루가 또 가네요.\n",
            "\n",
            "Q: 1지망 학교 떨어졌어\n",
            "A: 위로해 드립니다.\n",
            "\n",
            "Q: 3박4일 놀러가고 싶다\n",
            "A: 여행은 언제나 좋죠.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 데이터 로드 및 전처리 실행\n",
        "# 파일 경로를 실제 데이터가 있는 위치로 수정 필요\n",
        "file_path = '/Users/wansookim/Downloads/code_implementation/transformer_project_submit/data/ChatbotData.csv'\n",
        "\n",
        "# 함수 호출하여 전처리된 질문과 답변 리스트 받기\n",
        "questions, answers = load_and_preprocess_data(file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d5dfc612",
      "metadata": {
        "id": "d5dfc612"
      },
      "source": [
        "## Step 3: SentencePiece Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "id": "93XtZLrhKUU8",
      "metadata": {
        "id": "93XtZLrhKUU8"
      },
      "outputs": [],
      "source": [
        "def train_sentencepiece_model(questions, answers, model_prefix='/Users/wansookim/Downloads/code_implementation/transformer_project_submit', vocab_size=1200):\n",
        "    \"\"\"\n",
        "    SentencePiece 모델 학습\n",
        "    SentencePiece: 텍스트를 서브워드 단위로 분리하는 토크나이저\n",
        "    장점: OOV(Out-of-Vocabulary) 문제 해결, 한국어에 효과적\n",
        "    \"\"\"\n",
        "    print(\"=\" * 50)\n",
        "    print(\"SentencePiece 모델 학습 중...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # 모든 문장을 하나의 텍스트 파일로 저장 (SentencePiece 입력 형식)\n",
        "    all_sentences_path = '/Users/wansookim/Downloads/code_implementation/transformer_project_submit/sentencepiece'\n",
        "    with open(all_sentences_path, 'w', encoding='utf-8') as f:\n",
        "        # 질문과 답변을 모두 합쳐서 줄바꿈으로 구분하여 저장\n",
        "        f.write('\\n'.join(questions + answers))\n",
        "\n",
        "    # SentencePiece 학습 명령어 설정\n",
        "    cmd = f'--input={all_sentences_path} \\\n",
        "           --model_prefix={model_prefix} \\\n",
        "           --vocab_size={vocab_size} \\\n",
        "           --model_type=unigram \\\n",
        "           --max_sentence_length=999999 \\\n",
        "           --pad_id=0 \\\n",
        "           --unk_id=1 \\\n",
        "           --bos_id=2 \\\n",
        "           --eos_id=3 \\\n",
        "           --user_defined_symbols=[SEP],[CLS],[MASK]'\n",
        "    # --input: 학습 데이터 경로\n",
        "    # --model_prefix: 저장될 모델 파일명 접두사\n",
        "    # --vocab_size: 어휘 사전 크기 (8000개의 서브워드)\n",
        "    # --model_type: unigram 언어 모델 사용\n",
        "    # --pad_id: 패딩 토큰 ID (0)\n",
        "    # --unk_id: 미등록 토큰 ID (1)\n",
        "    # --bos_id: 문장 시작 토큰 ID (2)\n",
        "    # --eos_id: 문장 종료 토큰 ID (3)\n",
        "\n",
        "    # SentencePiece 모델 학습 실행\n",
        "    spm.SentencePieceTrainer.Train(cmd)\n",
        "\n",
        "    # 학습된 모델 파일 경로 생성\n",
        "    model_file = f\"{model_prefix}.model\"\n",
        "    print(f\"\\n모델 저장됨: {model_file}\")\n",
        "    return model_file\n",
        "\n",
        "\n",
        "class SentencePieceVocab:\n",
        "    \"\"\"\n",
        "    SentencePiece 모델 래퍼 클래스\n",
        "    목적: SentencePiece 모델을 쉽게 사용하기 위한 인터페이스 제공\n",
        "    \"\"\"\n",
        "    def __init__(self, sp_model_path):\n",
        "        # SentencePiece 프로세서 초기화\n",
        "        self.sp = spm.SentencePieceProcessor()\n",
        "        # 학습된 모델 로드\n",
        "        self.sp.Load(sp_model_path)\n",
        "\n",
        "        # 특수 토큰 ID 정의\n",
        "        self.PAD_ID = 0  # 패딩 (빈 공간 채우기)\n",
        "        self.UNK_ID = 1  # 미등록 단어\n",
        "        self.BOS_ID = 2  # 문장 시작 (Beginning Of Sentence)\n",
        "        self.EOS_ID = 3  # 문장 끝 (End Of Sentence)\n",
        "\n",
        "        # 토큰 문자열 -> ID 매핑\n",
        "        self.stoi = {'<pad>': 0, '<unk>': 1, '<s>': 2, '</s>': 3}\n",
        "\n",
        "        # ID -> 토큰 문자열 매핑 (전체 어휘)\n",
        "        self.itos = [self.sp.IdToPiece(i) for i in range(self.sp.GetPieceSize())]\n",
        "\n",
        "    def encode(self, sentence):\n",
        "        \"\"\"문장을 토큰 ID 리스트로 인코딩\"\"\"\n",
        "        return self.sp.EncodeAsIds(sentence)\n",
        "\n",
        "    def decode(self, ids):\n",
        "        \"\"\"\n",
        "        토큰 ID 리스트를 문장으로 디코딩\n",
        "        특수 토큰(pad, bos, eos)은 제외하고 디코딩\n",
        "        \"\"\"\n",
        "        return self.sp.DecodeIds([i for i in ids if i not in [0, 2, 3]])\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"어휘 사전 크기 반환\"\"\"\n",
        "        return self.sp.GetPieceSize()\n",
        "\n",
        "\n",
        "class ChatbotDataset(Dataset):\n",
        "    \"\"\"\n",
        "    PyTorch Dataset 클래스\n",
        "    목적: 질문-답변 쌍을 PyTorch 모델에 입력 가능한 형태로 변환\n",
        "    \"\"\"\n",
        "    def __init__(self, questions, answers, vocab, max_length=40):\n",
        "        # 데이터 저장\n",
        "        self.questions = questions\n",
        "        self.answers = answers\n",
        "        self.vocab = vocab  # SentencePiece vocab 객체\n",
        "        self.max_length = max_length  # 최대 시퀀스 길이 (잘림 방지)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"데이터셋 크기 반환\"\"\"\n",
        "        return len(self.questions)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        특정 인덱스의 데이터를 가져옴\n",
        "        반환: 토큰화된 질문(SRC)과 답변(TRG)\n",
        "        \"\"\"\n",
        "        # idx번째 질문과 답변 가져오기\n",
        "        q = self.questions[idx]\n",
        "        a = self.answers[idx]\n",
        "\n",
        "        # 질문 토큰화: [BOS] + 토큰들 + [EOS]\n",
        "        src = [self.vocab.BOS_ID] + self.vocab.encode(q) + [self.vocab.EOS_ID]\n",
        "\n",
        "        # 답변 토큰화: [BOS] + 토큰들 + [EOS]\n",
        "        trg = [self.vocab.BOS_ID] + self.vocab.encode(a) + [self.vocab.EOS_ID]\n",
        "\n",
        "        # PyTorch tensor로 변환 (dtype=long은 정수형, embedding 입력으로 필요)\n",
        "        return {\n",
        "            'SRC': torch.tensor(src[:self.max_length], dtype=torch.long),  # 최대 길이로 자르기\n",
        "            'TRG': torch.tensor(trg[:self.max_length], dtype=torch.long)\n",
        "        }\n",
        "\n",
        "\n",
        "def collate_fn(batch, pad_idx=0):\n",
        "    \"\"\"\n",
        "    DataLoader의 배치 생성 함수\n",
        "    목적: 서로 다른 길이의 시퀀스를 같은 길이로 패딩하여 배치 생성\n",
        "    \"\"\"\n",
        "    # 배치에서 SRC(질문)와 TRG(답변) 분리\n",
        "    src_batch = [item['SRC'] for item in batch]\n",
        "    trg_batch = [item['TRG'] for item in batch]\n",
        "\n",
        "    # 배치 내 최대 길이 찾기\n",
        "    src_max = max(len(s) for s in src_batch)\n",
        "    trg_max = max(len(t) for t in trg_batch)\n",
        "\n",
        "    # 각 시퀀스를 최대 길이에 맞춰 패딩\n",
        "    # 짧은 시퀀스는 뒤에 pad_idx(0)를 채워서 같은 길이로 만듦\n",
        "    # dtype=torch.long 명시: embedding 레이어는 정수형 입력 필요\n",
        "    src_padded = [torch.cat([s, torch.tensor([pad_idx]*(src_max-len(s)), dtype=torch.long)])\n",
        "                  for s in src_batch]\n",
        "    trg_padded = [torch.cat([t, torch.tensor([pad_idx]*(trg_max-len(t)), dtype=torch.long)])\n",
        "                  for t in trg_batch]\n",
        "\n",
        "    # 리스트의 텐서들을 하나의 텐서로 쌓기 (batch_size, seq_len)\n",
        "    return {'SRC': torch.stack(src_padded), 'TRG': torch.stack(trg_padded)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 246,
      "id": "X4ScpHrOKUU9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4ScpHrOKUU9",
        "outputId": "c9b7e97b-755b-4f68-b710-8c113268b747"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "SentencePiece 모델 학습 중...\n",
            "==================================================\n",
            "\n",
            "모델 저장됨: /Users/wansookim/Downloads/code_implementation/transformer_project_submit.model\n",
            "\n",
            "어휘 사전 크기: 1,200\n",
            "\n",
            "테스트 문장: 12시 땡!\n",
            "인코딩 결과 (처음 10개): [7, 680, 311, 55, 7, 1022, 115]...\n",
            "디코딩 결과: 12시 땡!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=/Users/wansookim/Downloads/code_implementation/transformer_project_submit/sentencepiece            --model_prefix=/Users/wansookim/Downloads/code_implementation/transformer_project_submit            --vocab_size=1200            --model_type=unigram            --max_sentence_length=999999            --pad_id=0            --unk_id=1            --bos_id=2            --eos_id=3            --user_defined_symbols=[SEP],[CLS],[MASK]\n",
            "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
            "trainer_spec {\n",
            "  input: /Users/wansookim/Downloads/code_implementation/transformer_project_submit/sentencepiece\n",
            "  input_format: \n",
            "  model_prefix: /Users/wansookim/Downloads/code_implementation/transformer_project_submit\n",
            "  model_type: UNIGRAM\n",
            "  vocab_size: 1200\n",
            "  self_test_sample_size: 0\n",
            "  character_coverage: 0.9995\n",
            "  input_sentence_size: 0\n",
            "  shuffle_input_sentence: 1\n",
            "  seed_sentencepiece_size: 1000000\n",
            "  shrinking_factor: 0.75\n",
            "  max_sentence_length: 999999\n",
            "  num_threads: 16\n",
            "  num_sub_iterations: 2\n",
            "  max_sentencepiece_length: 16\n",
            "  split_by_unicode_script: 1\n",
            "  split_by_number: 1\n",
            "  split_by_whitespace: 1\n",
            "  split_digits: 0\n",
            "  pretokenization_delimiter: \n",
            "  treat_whitespace_as_suffix: 0\n",
            "  allow_whitespace_only_pieces: 0\n",
            "  user_defined_symbols: [SEP]\n",
            "  user_defined_symbols: [CLS]\n",
            "  user_defined_symbols: [MASK]\n",
            "  required_chars: \n",
            "  byte_fallback: 0\n",
            "  vocabulary_output_piece_score: 1\n",
            "  train_extremely_large_corpus: 0\n",
            "  seed_sentencepieces_file: \n",
            "  hard_vocab_limit: 1\n",
            "  use_all_vocab: 0\n",
            "  unk_id: 1\n",
            "  bos_id: 2\n",
            "  eos_id: 3\n",
            "  pad_id: 0\n",
            "  unk_piece: <unk>\n",
            "  bos_piece: <s>\n",
            "  eos_piece: </s>\n",
            "  pad_piece: <pad>\n",
            "  unk_surface:  ⁇ \n",
            "  enable_differential_privacy: 0\n",
            "  differential_privacy_noise_level: 0\n",
            "  differential_privacy_clipping_threshold: 0\n",
            "}\n",
            "normalizer_spec {\n",
            "  name: nmt_nfkc\n",
            "  add_dummy_prefix: 1\n",
            "  remove_extra_whitespaces: 1\n",
            "  escape_whitespaces: 1\n",
            "  normalization_rule_tsv: \n",
            "}\n",
            "denormalizer_spec {}\n",
            "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
            "trainer_interface.cc(186) LOG(INFO) Loading corpus: /Users/wansookim/Downloads/code_implementation/transformer_project_submit/sentencepiece\n",
            "trainer_interface.cc(411) LOG(INFO) Loaded all 23646 sentences\n",
            "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\n",
            "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
            "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\n",
            "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\n",
            "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [SEP]\n",
            "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [CLS]\n",
            "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [MASK]\n",
            "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
            "trainer_interface.cc(541) LOG(INFO) all chars count=353346\n",
            "trainer_interface.cc(552) LOG(INFO) Done: 99.9505% characters are covered.\n",
            "trainer_interface.cc(562) LOG(INFO) Alphabet size=1081\n",
            "trainer_interface.cc(563) LOG(INFO) Final character coverage=0.999505\n",
            "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 23646 sentences.\n",
            "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
            "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=162511\n",
            "unigram_model_trainer.cc(312) LOG(INFO) Initialized 18854 seed sentencepieces\n",
            "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 23646\n",
            "trainer_interface.cc(611) LOG(INFO) Done! 21767\n",
            "unigram_model_trainer.cc(602) LOG(INFO) Using 21767 sentences for EM training\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=10901 obj=13.2232 num_tokens=46216 num_tokens/piece=4.23961\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9585 obj=12.117 num_tokens=46316 num_tokens/piece=4.83213\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=7188 obj=12.4735 num_tokens=49348 num_tokens/piece=6.86533\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=7187 obj=12.417 num_tokens=49382 num_tokens/piece=6.87102\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=5390 obj=12.9323 num_tokens=53504 num_tokens/piece=9.92653\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=5390 obj=12.8517 num_tokens=53504 num_tokens/piece=9.92653\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=4042 obj=13.5925 num_tokens=57912 num_tokens/piece=14.3276\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=4042 obj=13.4963 num_tokens=57922 num_tokens/piece=14.33\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=3031 obj=14.2864 num_tokens=62707 num_tokens/piece=20.6886\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=3031 obj=14.1763 num_tokens=62712 num_tokens/piece=20.6902\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=2273 obj=15.0025 num_tokens=67901 num_tokens/piece=29.8729\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=2273 obj=14.87 num_tokens=67903 num_tokens/piece=29.8737\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=1704 obj=15.9206 num_tokens=73528 num_tokens/piece=43.1502\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=1704 obj=15.745 num_tokens=73684 num_tokens/piece=43.2418\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=1320 obj=16.9886 num_tokens=80028 num_tokens/piece=60.6273\n",
            "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=1320 obj=16.756 num_tokens=80029 num_tokens/piece=60.628\n",
            "trainer_interface.cc(689) LOG(INFO) Saving model: /Users/wansookim/Downloads/code_implementation/transformer_project_submit.model\n",
            "trainer_interface.cc(701) LOG(INFO) Saving vocabs: /Users/wansookim/Downloads/code_implementation/transformer_project_submit.vocab\n"
          ]
        }
      ],
      "source": [
        "# ===== SentencePiece 모델 학습 및 어휘 사전 생성 =====\n",
        "\n",
        "# SentencePiece 모델 학습 실행\n",
        "model_file = train_sentencepiece_model(questions, answers)\n",
        "\n",
        "# Vocab 객체 생성 (토크나이저 래퍼)\n",
        "vocab = SentencePieceVocab(model_file)\n",
        "print(f\"\\n어휘 사전 크기: {len(vocab):,}\")  # 어휘에 포함된 총 토큰 수\n",
        "\n",
        "# 토크나이징 테스트\n",
        "test_sentence = questions[0]  # 첫 번째 질문으로 테스트\n",
        "encoded = vocab.encode(test_sentence)  # 문장 -> 토큰 ID로 인코딩\n",
        "decoded = vocab.decode(encoded)  # 토큰 ID -> 문장으로 디코딩\n",
        "\n",
        "# 인코딩/디코딩 결과 확인\n",
        "print(f\"\\n테스트 문장: {test_sentence}\")\n",
        "print(f\"인코딩 결과 (처음 10개): {encoded[:10]}...\")  # 토큰 ID 리스트\n",
        "print(f\"디코딩 결과: {decoded}\")  # 다시 문장으로 변환\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 247,
      "id": "wJmxylqUKUU9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJmxylqUKUU9",
        "outputId": "0702fda6-5c7d-4cc7-a792-1adc0ff37e18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "데이터 분할 완료\n",
            "==================================================\n",
            "Train: 9,458 쌍\n",
            "Val: 1,182 쌍\n",
            "Test: 1,183 쌍\n"
          ]
        }
      ],
      "source": [
        "# ===== 데이터 분할: Train / Validation / Test =====\n",
        "\n",
        "# 1단계: 전체 데이터를 Train(80%) + Temp(20%)로 분할\n",
        "train_q, temp_q, train_a, temp_a = train_test_split(\n",
        "    questions, answers,  # 전체 데이터\n",
        "    test_size=0.2,  # 20%를 temp로\n",
        "    random_state=42  # 재현성을 위한 랜덤 시드\n",
        ")\n",
        "\n",
        "# 2단계: Temp 데이터를 Validation(10%) + Test(10%)로 분할\n",
        "val_q, test_q, val_a, test_a = train_test_split(\n",
        "    temp_q, temp_a,  # temp 데이터 (전체의 20%)\n",
        "    test_size=0.5,  # temp의 50% = 전체의 10%\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# PyTorch Dataset 객체 생성\n",
        "train_dataset = ChatbotDataset(train_q, train_a, vocab, max_length=40)\n",
        "val_dataset = ChatbotDataset(val_q, val_a, vocab, max_length=40)\n",
        "test_dataset = ChatbotDataset(test_q, test_a, vocab, max_length=40)\n",
        "\n",
        "# DataLoader 생성 (배치 단위로 데이터 로드)\n",
        "train_iterator = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=64,  # 한 번에 32개씩 처리\n",
        "    shuffle=True,  # 학습 시 데이터 섞기 (과적합 방지)\n",
        "    collate_fn=lambda b: collate_fn(b, vocab.PAD_ID)  # 패딩 적용\n",
        ")\n",
        "\n",
        "valid_iterator = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,  # 검증 시에는 섞지 않음\n",
        "    collate_fn=lambda b: collate_fn(b, vocab.PAD_ID)\n",
        ")\n",
        "\n",
        "test_iterator = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=32,\n",
        "    shuffle=False,  # 테스트 시에도 섞지 않음\n",
        "    collate_fn=lambda b: collate_fn(b, vocab.PAD_ID)\n",
        ")\n",
        "\n",
        "# 데이터 분할 결과 출력\n",
        "print(\"=\" * 50)\n",
        "print(\"데이터 분할 완료\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Train: {len(train_q):,} 쌍\")  # 학습용\n",
        "print(f\"Val: {len(val_q):,} 쌍\")  # 검증용 (하이퍼파라미터 튜닝)\n",
        "print(f\"Test: {len(test_q):,} 쌍\")  # 최종 평가용\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d95eb9a6",
      "metadata": {
        "id": "d95eb9a6"
      },
      "source": [
        "## Step 4: Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 248,
      "id": "BsSLJeUZKUU9",
      "metadata": {
        "id": "BsSLJeUZKUU9"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    멀티 헤드 어텐션 (Multi-Head Attention)\n",
        "    논문: 'Attention Is All You Need' (Vaswani et al., 2017)\n",
        "\n",
        "    핵심 아이디어:\n",
        "    - 여러 개의 어텐션을 병렬로 수행 (다양한 관점에서 정보 추출)\n",
        "    - 각 헤드는 서로 다른 표현 부분공간에 집중\n",
        "    - 모든 헤드의 출력을 합쳐서 최종 출력 생성\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, emb_dim, num_heads, dropout=0.0, bias=False,\n",
        "                 encoder_decoder_attention=False, causal=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # 하이퍼파라미터 저장\n",
        "        self.emb_dim = emb_dim  # 임베딩 차원 (전체 모델의 차원)\n",
        "        self.num_heads = num_heads  # 어텐션 헤드 개수\n",
        "        self.dropout = dropout  # 드롭아웃 비율\n",
        "        self.head_dim = emb_dim // num_heads  # 각 헤드의 차원\n",
        "\n",
        "        # emb_dim이 num_heads로 나누어 떨어지는지 확인\n",
        "        # 예: emb_dim=64, num_heads=8 → head_dim=8 (OK)\n",
        "        assert self.head_dim * num_heads == self.emb_dim, \"emb_dim은 num_heads로 나누어떨어져야 함\"\n",
        "\n",
        "        # 어텐션 타입 설정\n",
        "        self.encoder_decoder_attention = encoder_decoder_attention  # 인코더-디코더 간 어텐션 여부\n",
        "        self.causal = causal  # 인과적 마스킹 여부 (미래 토큰 참조 금지)\n",
        "\n",
        "        # Query, Key, Value 투영 레이어\n",
        "        # 입력을 Q, K, V로 변환하는 선형 변환\n",
        "        self.q_proj = nn.Linear(emb_dim, emb_dim, bias=bias)  # Query 투영\n",
        "        self.k_proj = nn.Linear(emb_dim, emb_dim, bias=bias)  # Key 투영\n",
        "        self.v_proj = nn.Linear(emb_dim, emb_dim, bias=bias)  # Value 투영\n",
        "\n",
        "        # 최종 출력 투영 레이어\n",
        "        self.out_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
        "\n",
        "    def transpose_for_scores(self, x):\n",
        "        \"\"\"\n",
        "        텐서를 멀티 헤드 어텐션 계산에 적합한 형태로 변환\n",
        "\n",
        "        입력 형태: (batch_size, seq_len, emb_dim)\n",
        "        출력 형태: (batch_size, num_heads, seq_len, head_dim)\n",
        "\n",
        "        이렇게 하면 각 헤드가 독립적으로 어텐션을 계산할 수 있음\n",
        "        \"\"\"\n",
        "        # (batch_size, seq_len, emb_dim) → (batch_size, seq_len, num_heads, head_dim)\n",
        "        new_x_shape = x.size()[:-1] + (self.num_heads, self.head_dim,)\n",
        "        x = x.view(*new_x_shape)\n",
        "\n",
        "        # (batch_size, seq_len, num_heads, head_dim) → (batch_size, num_heads, seq_len, head_dim)\n",
        "        # permute로 헤드 차원을 앞으로 이동\n",
        "        return x.permute(0, 2, 1, 3)\n",
        "\n",
        "    def forward(self, query, key, attention_mask=None):\n",
        "        \"\"\"\n",
        "        Forward pass: 어텐션 메커니즘 수행\n",
        "\n",
        "        Args:\n",
        "            query: 쿼리 텐서 (무엇을 찾고 싶은지)\n",
        "            key: 키/밸류 텐서 (어디서 정보를 가져올지)\n",
        "            attention_mask: 어텐션 마스크 (특정 위치 참조 금지)\n",
        "        \"\"\"\n",
        "        # Query 투영: (batch, seq_len, emb_dim)\n",
        "        q = self.q_proj(query)\n",
        "\n",
        "        if self.encoder_decoder_attention:\n",
        "            # 크로스 어텐션: Query는 디코더, Key/Value는 인코더에서\n",
        "            k = self.k_proj(key)\n",
        "            v = self.v_proj(key)\n",
        "        else:\n",
        "            # 셀프 어텐션: Query, Key, Value 모두 같은 입력에서\n",
        "            k = self.k_proj(query)\n",
        "            v = self.v_proj(query)\n",
        "\n",
        "        # 멀티 헤드 형태로 변환\n",
        "        q = self.transpose_for_scores(q)  # (batch, num_heads, seq_len, head_dim)\n",
        "        k = self.transpose_for_scores(k)\n",
        "        v = self.transpose_for_scores(v)\n",
        "\n",
        "        # 어텐션 스코어 계산: Q와 K의 내적\n",
        "        # (batch, num_heads, seq_len_q, head_dim) @ (batch, num_heads, head_dim, seq_len_k)\n",
        "        # → (batch, num_heads, seq_len_q, seq_len_k)\n",
        "        attn_weights = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(self.head_dim)\n",
        "        # sqrt(head_dim)으로 나누는 이유: 스케일 조정 (그래디언트 안정화)\n",
        "\n",
        "        # 어텐션 마스크 적용 (필요한 경우)\n",
        "        if attention_mask is not None:\n",
        "            if self.causal:\n",
        "                # 인과적 마스킹: 미래 토큰을 볼 수 없도록 (디코더 self-attention)\n",
        "                # -inf로 설정하면 softmax 후 0이 됨\n",
        "                attn_weights = attn_weights.masked_fill(\n",
        "                    attention_mask.unsqueeze(0).unsqueeze(1), float(\"-inf\")\n",
        "                )\n",
        "            else:\n",
        "                # 패딩 마스킹: 패딩 토큰을 참조하지 않도록\n",
        "                attn_weights = attn_weights.masked_fill(\n",
        "                    attention_mask.unsqueeze(1).unsqueeze(2), float(\"-inf\")\n",
        "                )\n",
        "\n",
        "        # Softmax로 어텐션 확률 계산 (각 위치에 얼마나 집중할지)\n",
        "        attn_weights = F.softmax(attn_weights, dim=-1)  # 합이 1이 되도록\n",
        "\n",
        "        # 드롭아웃 적용 (학습 시 정규화)\n",
        "        attn_probs = F.dropout(attn_weights, p=self.dropout, training=self.training)\n",
        "\n",
        "        # 어텐션 가중치와 Value의 가중합 계산\n",
        "        # (batch, num_heads, seq_len, seq_len) @ (batch, num_heads, seq_len, head_dim)\n",
        "        # → (batch, num_heads, seq_len, head_dim)\n",
        "        attn_output = torch.matmul(attn_probs, v)\n",
        "\n",
        "        # 원래 형태로 되돌리기\n",
        "        # (batch, num_heads, seq_len, head_dim) → (batch, seq_len, num_heads, head_dim)\n",
        "        attn_output = attn_output.permute(0, 2, 1, 3).contiguous()\n",
        "\n",
        "        # 모든 헤드를 연결 (concatenate)\n",
        "        # (batch, seq_len, num_heads, head_dim) → (batch, seq_len, emb_dim)\n",
        "        concat_attn_output_shape = attn_output.size()[:-2] + (self.emb_dim,)\n",
        "        attn_output = attn_output.view(*concat_attn_output_shape)\n",
        "\n",
        "        # 최종 선형 투영\n",
        "        attn_output = self.out_proj(attn_output)\n",
        "\n",
        "        # 출력: 어텐션 결과와 어텐션 가중치 (시각화용)\n",
        "        return attn_output, attn_weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 249,
      "id": "Ic0RsbXFKUU-",
      "metadata": {
        "id": "Ic0RsbXFKUU-"
      },
      "outputs": [],
      "source": [
        "class PositionWiseFeedForward(nn.Module):\n",
        "    \"\"\"\n",
        "    위치별 피드포워드 네트워크 (Position-wise Feed-Forward Network)\n",
        "\n",
        "    Transformer의 각 위치(토큰)에 독립적으로 적용되는 2층 fully-connected 네트워크\n",
        "    역할: 어텐션으로 모은 정보를 비선형 변환하여 더 풍부한 표현 학습\n",
        "\n",
        "    구조: Linear → ReLU → Dropout → Linear → Dropout → Residual Connection\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, emb_dim, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        # 첫 번째 선형 레이어: emb_dim → d_ff (차원 확장)\n",
        "        # 보통 d_ff = 4 * emb_dim (예: 64 → 256)\n",
        "        self.w_1 = nn.Linear(emb_dim, d_ff)\n",
        "\n",
        "        # 두 번째 선형 레이어: d_ff → emb_dim (차원 축소)\n",
        "        self.w_2 = nn.Linear(d_ff, emb_dim)\n",
        "\n",
        "        self.dropout = dropout  # 드롭아웃 비율\n",
        "        self.activation = nn.ReLU()  # 활성화 함수 (비선형성 추가)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass\n",
        "\n",
        "        입력: (batch_size, seq_len, emb_dim)\n",
        "        출력: (batch_size, seq_len, emb_dim)\n",
        "        \"\"\"\n",
        "        # Residual connection을 위해 입력 저장\n",
        "        residual = x\n",
        "\n",
        "        # 1. 차원 확장 및 활성화\n",
        "        x = self.activation(self.w_1(x))  # (batch, seq_len, emb_dim) → (batch, seq_len, d_ff)\n",
        "\n",
        "        # 2. 드롭아웃 (학습 시 정규화)\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        # 3. 차원 축소 (원래 크기로)\n",
        "        x = self.w_2(x)  # (batch, seq_len, d_ff) → (batch, seq_len, emb_dim)\n",
        "\n",
        "        # 4. 드롭아웃\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "\n",
        "        # 5. Residual connection (입력을 출력에 더함)\n",
        "        # 이유: 그래디언트 소실 방지, 학습 안정화\n",
        "        return x + residual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 250,
      "id": "ErN_GrmvKUU-",
      "metadata": {
        "id": "ErN_GrmvKUU-"
      },
      "outputs": [],
      "source": [
        "class SinusoidalPositionalEmbedding(nn.Embedding):\n",
        "    \"\"\"\n",
        "    사인/코사인 위치 임베딩 (Sinusoidal Positional Embedding)\n",
        "\n",
        "    목적: 토큰의 순서 정보를 모델에 제공\n",
        "    이유: Transformer는 순서를 고려하지 않는 구조이므로, 위치 정보를 명시적으로 추가해야 함\n",
        "\n",
        "    수식:\n",
        "    PE(pos, 2i) = sin(pos / 10000^(2i/d_model))\n",
        "    PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
        "\n",
        "    특징:\n",
        "    - 학습 불필요 (고정된 수식)\n",
        "    - 서로 다른 주기의 sin/cos 조합으로 고유한 위치 표현\n",
        "    - 상대적 위치 관계도 학습 가능\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, num_positions, embedding_dim, padding_idx=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            num_positions: 최대 위치 개수 (최대 시퀀스 길이)\n",
        "            embedding_dim: 임베딩 차원\n",
        "            padding_idx: 패딩 인덱스 (사용 안 함)\n",
        "        \"\"\"\n",
        "        # 부모 클래스(nn.Embedding) 초기화\n",
        "        super().__init__(num_positions, embedding_dim)\n",
        "\n",
        "        # weight 파라미터를 사인/코사인 값으로 초기화\n",
        "        self._init_weight(self.weight)\n",
        "\n",
        "    @staticmethod\n",
        "    def _init_weight(out):\n",
        "        \"\"\"\n",
        "        위치 임베딩을 사인/코사인 패턴으로 초기화\n",
        "\n",
        "        Args:\n",
        "            out: 초기화할 파라미터 텐서 (num_positions, embedding_dim)\n",
        "        \"\"\"\n",
        "        n_pos, embed_dim = out.shape  # 위치 개수, 임베딩 차원\n",
        "\n",
        "        # 빈 텐서 생성 (임시)\n",
        "        position_enc = torch.zeros(n_pos, embed_dim)\n",
        "\n",
        "        # 각 위치에 대해\n",
        "        for pos in range(n_pos):\n",
        "            # 짝수 인덱스는 sin, 홀수 인덱스는 cos\n",
        "            for i in range(0, embed_dim, 2):  # 2씩 증가 (짝수만)\n",
        "                # 짝수 인덱스: sin 함수\n",
        "                position_enc[pos, i] = math.sin(pos / (10000 ** (i / embed_dim)))\n",
        "\n",
        "                # 홀수 인덱스: cos 함수 (경계 체크)\n",
        "                if i + 1 < embed_dim:\n",
        "                    position_enc[pos, i + 1] = math.cos(pos / (10000 ** ((i + 1) / embed_dim)))\n",
        "\n",
        "        # 계산된 값을 파라미터의 data에 복사 (in-place)\n",
        "        # .data.copy_()를 사용하면 autograd 그래프를 건드리지 않음\n",
        "        out.data.copy_(position_enc)\n",
        "\n",
        "        # 위치 임베딩은 학습하지 않음 (고정)\n",
        "        out.requires_grad = False\n",
        "\n",
        "    @torch.no_grad()  # 그래디언트 계산 불필요\n",
        "    def forward(self, input_ids):\n",
        "        \"\"\"\n",
        "        Forward pass: 입력 시퀀스 길이에 맞는 위치 임베딩 반환\n",
        "\n",
        "        Args:\n",
        "            input_ids: 입력 토큰 ID (batch_size, seq_len)\n",
        "\n",
        "        Returns:\n",
        "            위치 임베딩: (1, seq_len, embedding_dim) 또는 (seq_len, embedding_dim)\n",
        "        \"\"\"\n",
        "        bsz, seq_len = input_ids.shape[:2]  # 배치 크기, 시퀀스 길이\n",
        "\n",
        "        # 0부터 seq_len-1까지의 위치 인덱스 생성\n",
        "        # device를 weight와 같은 곳에 두기 (GPU/CPU 일치)\n",
        "        positions = torch.arange(seq_len, dtype=torch.long, device=self.weight.device)\n",
        "\n",
        "        # nn.Embedding의 forward를 호출하여 위치 임베딩 가져오기\n",
        "        return super().forward(positions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "id": "igoPVt7MKUU-",
      "metadata": {
        "id": "igoPVt7MKUU-"
      },
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer 인코더의 단일 레이어\n",
        "\n",
        "    구조:\n",
        "    1. Multi-Head Self-Attention\n",
        "    2. Layer Normalization\n",
        "    3. Position-wise Feed-Forward\n",
        "    4. Layer Normalization\n",
        "\n",
        "    각 서브레이어 후에 residual connection 적용\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        # 셀프 어텐션 레이어\n",
        "        # 입력 시퀀스의 각 토큰이 다른 모든 토큰과 상호작용\n",
        "        self.self_attn = MultiHeadAttention(\n",
        "            emb_dim=config.emb_dim,  # 임베딩 차원\n",
        "            num_heads=config.num_heads,  # 어텐션 헤드 개수\n",
        "            dropout=config.attention_dropout,  # 어텐션 드롭아웃\n",
        "            causal=False  # 인코더는 양방향 (모든 토큰 참조 가능)\n",
        "        )\n",
        "\n",
        "        # 레이어 정규화 (Layer Normalization)\n",
        "        # 각 샘플의 특성들을 정규화 (배치 정규화와 다름)\n",
        "        self.norm1 = nn.LayerNorm(config.emb_dim)\n",
        "\n",
        "        # 피드포워드 네트워크\n",
        "        self.ffn = PositionWiseFeedForward(\n",
        "            emb_dim=config.emb_dim,\n",
        "            d_ff=config.ffn_dim,  # 중간 확장 차원 (보통 4*emb_dim)\n",
        "            dropout=config.dropout\n",
        "        )\n",
        "\n",
        "        # 두 번째 레이어 정규화\n",
        "        self.norm2 = nn.LayerNorm(config.emb_dim)\n",
        "\n",
        "        self.dropout = config.dropout\n",
        "\n",
        "    def forward(self, x, attention_mask=None):\n",
        "        \"\"\"\n",
        "        Forward pass\n",
        "\n",
        "        Args:\n",
        "            x: 입력 (batch_size, seq_len, emb_dim)\n",
        "            attention_mask: 패딩 마스크 (batch_size, seq_len)\n",
        "        \"\"\"\n",
        "        # 1. Multi-Head Self-Attention\n",
        "        # 입력을 Query, Key, Value로 모두 사용 (셀프 어텐션)\n",
        "        attn_output, attn_weights = self.self_attn(\n",
        "            query=x,  # Query\n",
        "            key=x,  # Key = Query (셀프 어텐션)\n",
        "            attention_mask=attention_mask  # 패딩 위치 마스킹\n",
        "        )\n",
        "\n",
        "        # Residual connection + Dropout\n",
        "        x = x + F.dropout(attn_output, p=self.dropout, training=self.training)\n",
        "\n",
        "        # Layer Normalization (Post-LN 방식)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # 2. Position-wise Feed-Forward Network\n",
        "        # (내부에 이미 residual connection 포함)\n",
        "        x = self.ffn(x)\n",
        "\n",
        "        # Layer Normalization\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        return x, attn_weights  # 출력과 어텐션 가중치 반환\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 252,
      "id": "VwU1alcfKUU-",
      "metadata": {
        "id": "VwU1alcfKUU-"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer 인코더\n",
        "\n",
        "    입력 시퀀스를 받아서 문맥을 이해한 표현(representation)으로 변환\n",
        "    여러 개의 EncoderLayer를 쌓아서 구성\n",
        "\n",
        "    처리 과정:\n",
        "    1. 토큰 임베딩 + 위치 임베딩\n",
        "    2. N개의 EncoderLayer 통과\n",
        "    3. 최종 인코딩된 표현 출력\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, embed_tokens):\n",
        "        super().__init__()\n",
        "\n",
        "        # 패딩 인덱스 저장 (어텐션에서 마스킹할 때 사용)\n",
        "        self.padding_idx = embed_tokens.padding_idx\n",
        "\n",
        "        # 토큰 임베딩 레이어 (단어 -> 벡터)\n",
        "        self.embed_tokens = embed_tokens\n",
        "\n",
        "        # 위치 임베딩 레이어 (순서 정보 제공)\n",
        "        self.embed_positions = SinusoidalPositionalEmbedding(\n",
        "            config.max_position_embeddings,  # 최대 시퀀스 길이\n",
        "            config.emb_dim,  # 임베딩 차원\n",
        "            self.padding_idx\n",
        "        )\n",
        "\n",
        "        # N개의 EncoderLayer 스택\n",
        "        # ModuleList: 여러 레이어를 리스트로 관리 (자동으로 파라미터 등록)\n",
        "        self.layers = nn.ModuleList([\n",
        "            EncoderLayer(config) for _ in range(config.encoder_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        \"\"\"\n",
        "        Forward pass\n",
        "\n",
        "        Args:\n",
        "            input_ids: 입력 토큰 ID (batch_size, seq_len)\n",
        "            attention_mask: 패딩 마스크 (batch_size, seq_len)\n",
        "\n",
        "        Returns:\n",
        "            인코딩된 표현 (batch_size, seq_len, emb_dim)\n",
        "            어텐션 스코어 리스트\n",
        "        \"\"\"\n",
        "        # 1. 토큰 임베딩: 토큰 ID -> 임베딩 벡터\n",
        "        # (batch_size, seq_len) → (batch_size, seq_len, emb_dim)\n",
        "        inputs_embeds = self.embed_tokens(input_ids)\n",
        "\n",
        "        # 2. 위치 임베딩: 각 위치의 위치 정보\n",
        "        # (seq_len, emb_dim)\n",
        "        embed_pos = self.embed_positions(input_ids)\n",
        "\n",
        "        # 3. 토큰 임베딩 + 위치 임베딩\n",
        "        # 두 임베딩을 더해서 최종 입력 표현 생성\n",
        "        x = inputs_embeds + embed_pos\n",
        "\n",
        "        # 어텐션 스코어를 저장할 리스트 (시각화나 분석용)\n",
        "        attention_scores = []\n",
        "\n",
        "        # 4. 모든 EncoderLayer를 순차적으로 통과\n",
        "        for layer in self.layers:\n",
        "            # 각 레이어의 출력이 다음 레이어의 입력이 됨\n",
        "            x, attn = layer(x, attention_mask=attention_mask)\n",
        "            attention_scores.append(attn)  # 각 레이어의 어텐션 저장\n",
        "\n",
        "        # 최종 인코딩된 표현과 모든 레이어의 어텐션 반환\n",
        "        return x, attention_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "id": "af-HTCxuKUU-",
      "metadata": {
        "id": "af-HTCxuKUU-"
      },
      "outputs": [],
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer 디코더의 단일 레이어\n",
        "\n",
        "    구조 (3개의 서브레이어):\n",
        "    1. Masked Multi-Head Self-Attention (미래 토큰 참조 불가)\n",
        "    2. Multi-Head Cross-Attention (인코더 출력 참조)\n",
        "    3. Position-wise Feed-Forward Network\n",
        "\n",
        "    각 서브레이어마다 residual connection + layer normalization\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "\n",
        "        # 1. Masked Self-Attention\n",
        "        # 디코더의 각 위치는 이전 위치들만 참조 가능 (causal=True)\n",
        "        self.self_attn = MultiHeadAttention(\n",
        "            emb_dim=config.emb_dim,\n",
        "            num_heads=config.num_heads,\n",
        "            dropout=config.attention_dropout,\n",
        "            causal=True  # 미래 토큰 마스킹\n",
        "        )\n",
        "        self.norm1 = nn.LayerNorm(config.emb_dim)\n",
        "\n",
        "        # 2. Cross-Attention (Encoder-Decoder Attention)\n",
        "        # Query: 디코더, Key/Value: 인코더 출력\n",
        "        self.cross_attn = MultiHeadAttention(\n",
        "            emb_dim=config.emb_dim,\n",
        "            num_heads=config.num_heads,\n",
        "            dropout=config.attention_dropout,\n",
        "            encoder_decoder_attention=True,  # 크로스 어텐션 활성화\n",
        "            causal=False  # 인코더 출력은 모두 참조 가능\n",
        "        )\n",
        "        self.norm2 = nn.LayerNorm(config.emb_dim)\n",
        "\n",
        "        # 3. Feed-Forward Network\n",
        "        self.ffn = PositionWiseFeedForward(\n",
        "            emb_dim=config.emb_dim,\n",
        "            d_ff=config.ffn_dim,\n",
        "            dropout=config.dropout\n",
        "        )\n",
        "        self.norm3 = nn.LayerNorm(config.emb_dim)\n",
        "\n",
        "        self.dropout = config.dropout\n",
        "\n",
        "    def forward(self, x, encoder_output, encoder_attention_mask=None, decoder_causal_mask=None):\n",
        "        \"\"\"\n",
        "        Forward pass\n",
        "\n",
        "        Args:\n",
        "            x: 디코더 입력 (batch_size, tgt_len, emb_dim)\n",
        "            encoder_output: 인코더 출력 (batch_size, src_len, emb_dim)\n",
        "            encoder_attention_mask: 인코더 패딩 마스크\n",
        "            decoder_causal_mask: 디코더 인과 마스크 (미래 마스킹)\n",
        "        \"\"\"\n",
        "        # 1. Masked Self-Attention\n",
        "        # 현재까지 생성된 토큰들끼리만 어텐션\n",
        "        self_attn_output, self_attn_weights = self.self_attn(\n",
        "            query=x,\n",
        "            key=x,  # 셀프 어텐션\n",
        "            attention_mask=decoder_causal_mask  # 미래 마스킹\n",
        "        )\n",
        "\n",
        "        # Residual + Dropout + LayerNorm\n",
        "        x = x + F.dropout(self_attn_output, p=self.dropout, training=self.training)\n",
        "        x = self.norm1(x)\n",
        "\n",
        "        # 2. Cross-Attention\n",
        "        # Query: 디코더, Key/Value: 인코더\n",
        "        # 디코더가 인코더의 정보를 참조\n",
        "        cross_attn_output, cross_attn_weights = self.cross_attn(\n",
        "            query=x,  # 디코더의 현재 상태\n",
        "            key=encoder_output,  # 인코더의 출력 (소스 문장 정보)\n",
        "            attention_mask=encoder_attention_mask  # 소스 패딩 마스킹\n",
        "        )\n",
        "\n",
        "        # Residual + Dropout + LayerNorm\n",
        "        x = x + F.dropout(cross_attn_output, p=self.dropout, training=self.training)\n",
        "        x = self.norm2(x)\n",
        "\n",
        "        # 3. Feed-Forward Network\n",
        "        x = self.ffn(x)\n",
        "        x = self.norm3(x)\n",
        "\n",
        "        # 출력과 어텐션 가중치 반환\n",
        "        return x, (self_attn_weights, cross_attn_weights)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "id": "SvHC5_xaKUU_",
      "metadata": {
        "id": "SvHC5_xaKUU_"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer 디코더\n",
        "\n",
        "    역할:\n",
        "    - 인코더의 출력을 참조하면서 순차적으로 답변 생성\n",
        "    - 이전에 생성한 토큰들과 인코더 정보를 활용\n",
        "\n",
        "    처리 과정:\n",
        "    1. 타겟 토큰 임베딩 + 위치 임베딩\n",
        "    2. N개의 DecoderLayer 통과\n",
        "    3. 다음 토큰 예측을 위한 표현 출력\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config, embed_tokens):\n",
        "        super().__init__()\n",
        "\n",
        "        # 패딩 인덱스\n",
        "        self.padding_idx = embed_tokens.padding_idx\n",
        "\n",
        "        # 타겟 토큰 임베딩 (답변 단어 -> 벡터)\n",
        "        self.embed_tokens = embed_tokens\n",
        "\n",
        "        # 위치 임베딩\n",
        "        self.embed_positions = SinusoidalPositionalEmbedding(\n",
        "            config.max_position_embeddings,\n",
        "            config.emb_dim,\n",
        "            self.padding_idx\n",
        "        )\n",
        "\n",
        "        # N개의 DecoderLayer 스택\n",
        "        self.layers = nn.ModuleList([\n",
        "            DecoderLayer(config) for _ in range(config.decoder_layers)\n",
        "        ])\n",
        "\n",
        "    def forward(self, input_ids, encoder_output,\n",
        "                encoder_attention_mask=None, decoder_causal_mask=None):\n",
        "        \"\"\"\n",
        "        Forward pass\n",
        "\n",
        "        Args:\n",
        "            input_ids: 타겟 토큰 ID (batch_size, tgt_len)\n",
        "            encoder_output: 인코더 출력 (batch_size, src_len, emb_dim)\n",
        "            encoder_attention_mask: 소스 패딩 마스크\n",
        "            decoder_causal_mask: 디코더 인과 마스크\n",
        "\n",
        "        Returns:\n",
        "            디코더 출력 (batch_size, tgt_len, emb_dim)\n",
        "            어텐션 스코어 리스트\n",
        "        \"\"\"\n",
        "        # 1. 타겟 토큰 임베딩\n",
        "        inputs_embeds = self.embed_tokens(input_ids)\n",
        "\n",
        "        # 2. 위치 임베딩\n",
        "        embed_pos = self.embed_positions(input_ids)\n",
        "\n",
        "        # 3. 토큰 임베딩 + 위치 임베딩\n",
        "        x = inputs_embeds + embed_pos\n",
        "\n",
        "        # 어텐션 스코어 저장\n",
        "        attention_scores = []\n",
        "\n",
        "        # 4. 모든 DecoderLayer 통과\n",
        "        for layer in self.layers:\n",
        "            # 각 레이어는 셀프 어텐션 + 크로스 어텐션 + FFN 수행\n",
        "            x, attn = layer(\n",
        "                x,  # 디코더 입력\n",
        "                encoder_output,  # 인코더 출력 (소스 정보)\n",
        "                encoder_attention_mask=encoder_attention_mask,\n",
        "                decoder_causal_mask=decoder_causal_mask\n",
        "            )\n",
        "            attention_scores.append(attn)  # (self_attn, cross_attn) 튜플\n",
        "\n",
        "        return x, attention_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "id": "a8_zWx3-KUU_",
      "metadata": {
        "id": "a8_zWx3-KUU_"
      },
      "outputs": [],
      "source": [
        "class Transformer(nn.Module):\n",
        "    \"\"\"\n",
        "    완전한 Transformer 모델 (Sequence-to-Sequence)\n",
        "\n",
        "    구조:\n",
        "    1. 소스/타겟 임베딩 레이어\n",
        "    2. Encoder (입력 인코딩)\n",
        "    3. Decoder (출력 생성)\n",
        "    4. 최종 출력 레이어 (어휘 확률 분포)\n",
        "\n",
        "    사용 예:\n",
        "    - 기계 번역 (영어 -> 한국어)\n",
        "    - 대화 시스템 (질문 -> 답변)\n",
        "    - 요약, 생성 등\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab, config):\n",
        "        super().__init__()\n",
        "\n",
        "        # 설정 저장\n",
        "        self.vocab = vocab  # 어휘 사전\n",
        "        self.config = config\n",
        "\n",
        "        # 소스(입력) 임베딩 레이어\n",
        "        # len(vocab.itos): 전체 어휘 크기\n",
        "        # padding_idx: 패딩 토큰은 임베딩하지 않음 (그래디언트 0)\n",
        "        self.enc_embedding = nn.Embedding(\n",
        "            len(vocab.itos), config.emb_dim, padding_idx=vocab.stoi['<pad>']\n",
        "        )\n",
        "\n",
        "        # 타겟(출력) 임베딩 레이어\n",
        "        self.dec_embedding = nn.Embedding(\n",
        "            len(vocab.itos), config.emb_dim, padding_idx=vocab.stoi['<pad>']\n",
        "        )\n",
        "\n",
        "        # Encoder와 Decoder 초기화\n",
        "        self.encoder = Encoder(config, self.enc_embedding)\n",
        "        self.decoder = Decoder(config, self.dec_embedding)\n",
        "\n",
        "        # 출력 레이어: 임베딩 차원 -> 어휘 크기\n",
        "        # 각 위치에서 다음 토큰의 확률 분포 생성\n",
        "        self.prediction_head = nn.Linear(config.emb_dim, len(vocab.itos))\n",
        "\n",
        "    def generate_mask(self, src, trg):\n",
        "        \"\"\"\n",
        "        어텐션 마스크 생성\n",
        "\n",
        "        1. 인코더 패딩 마스크: 소스 문장의 패딩 위치 표시\n",
        "        2. 디코더 인과 마스크: 미래 토큰 참조 방지\n",
        "\n",
        "        Args:\n",
        "            src: 소스 토큰 ID (batch_size, src_len)\n",
        "            trg: 타겟 토큰 ID (batch_size, tgt_len)\n",
        "        \"\"\"\n",
        "        # 1. 인코더 패딩 마스크\n",
        "        # 패딩 토큰(0)인 위치를 True로 표시\n",
        "        # True인 위치는 어텐션 계산 시 무시됨\n",
        "        enc_attention_mask = (src == self.vocab.stoi['<pad>'])\n",
        "\n",
        "        # 2. 디코더 인과 마스크 (Causal Mask)\n",
        "        # 각 위치에서 이후 위치를 볼 수 없도록 상삼각 행렬 생성\n",
        "        tgt_len = trg.size(1)\n",
        "        # torch.triu: 상삼각 행렬 (대각선 위쪽만 1)\n",
        "        # diagonal=1: 대각선 바로 위부터\n",
        "        # 예: [[0, 1, 1],\n",
        "        #      [0, 0, 1],\n",
        "        #      [0, 0, 0]]\n",
        "        dec_causal_mask = torch.triu(\n",
        "            torch.ones(tgt_len, tgt_len, dtype=torch.bool, device=trg.device),\n",
        "            diagonal=1\n",
        "        )\n",
        "        # True인 위치는 참조 불가 (미래 토큰)\n",
        "\n",
        "        return enc_attention_mask, dec_causal_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        \"\"\"\n",
        "        Forward pass: 소스에서 타겟으로 변환\n",
        "\n",
        "        Args:\n",
        "            src: 소스 시퀀스 (batch_size, src_len) - 질문\n",
        "            trg: 타겟 시퀀스 (batch_size, tgt_len) - 답변\n",
        "\n",
        "        Returns:\n",
        "            output: 예측 로짓 (batch_size, tgt_len, vocab_size)\n",
        "            encoder_attention_scores: 인코더 어텐션\n",
        "            decoder_attention_scores: 디코더 어텐션\n",
        "        \"\"\"\n",
        "        # 1. 마스크 생성\n",
        "        enc_attention_mask, dec_causal_mask = self.generate_mask(src, trg)\n",
        "\n",
        "        # 2. 인코더: 소스 문장 인코딩\n",
        "        # 입력 질문을 이해한 표현으로 변환\n",
        "        encoder_output, encoder_attention_scores = self.encoder(\n",
        "            input_ids=src,\n",
        "            attention_mask=enc_attention_mask\n",
        "        )\n",
        "\n",
        "        # 3. 디코더: 타겟 문장 생성\n",
        "        # 인코더 출력을 참조하면서 답변 생성\n",
        "        decoder_output, decoder_attention_scores = self.decoder(\n",
        "            trg,  # 타겟 입력 (teacher forcing)\n",
        "            encoder_output,  # 인코더 출력 (소스 정보)\n",
        "            encoder_attention_mask=enc_attention_mask,  # 소스 패딩\n",
        "            decoder_causal_mask=dec_causal_mask,  # 미래 마스킹\n",
        "        )\n",
        "\n",
        "        # 4. 최종 출력: 어휘 확률 분포\n",
        "        # (batch_size, tgt_len, emb_dim) → (batch_size, tgt_len, vocab_size)\n",
        "        decoder_output = self.prediction_head(decoder_output)\n",
        "\n",
        "        return decoder_output, encoder_attention_scores, decoder_attention_scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 256,
      "id": "c4ZxXsD4KUU_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4ZxXsD4KUU_",
        "outputId": "5a7f84aa-b681-4514-dde7-ee8a9a722ada"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "모델 파라미터 수: 6,463,664\n"
          ]
        }
      ],
      "source": [
        "# ===== 모델 설정 및 초기화 =====\n",
        "\n",
        "# 하이퍼파라미터 설정\n",
        "config = easydict.EasyDict({\n",
        "    # 모델 차원\n",
        "    \"emb_dim\": 256,  # 임베딩 차원 (단어를 64차원 벡터로 표현)\n",
        "    \"ffn_dim\": 1024,  # Feed-Forward 중간 차원 (보통 emb_dim의 4배)\n",
        "\n",
        "    # 어텐션 설정\n",
        "    \"num_heads\": 8,  # 멀티 헤드 어텐션의 헤드 개수\n",
        "    \"attention_dropout\": 0.1,  # 어텐션 가중치 드롭아웃\n",
        "\n",
        "    # 레이어 개수\n",
        "    \"encoder_layers\": 3,  # 인코더 레이어 수 (더 깊을수록 표현력 증가)\n",
        "    \"decoder_layers\": 3,  # 디코더 레이어 수\n",
        "\n",
        "    # 기타\n",
        "    \"dropout\": 0.35,  # 일반 드롭아웃 (과적합 방지)\n",
        "    \"max_position_embeddings\": 40  # 최대 시퀀스 길이\n",
        "})\n",
        "\n",
        "# 모델 생성\n",
        "model = Transformer(vocab, config)\n",
        "\n",
        "# 모델을 디바이스로 이동 (GPU/MPS 사용 가능하면 사용)\n",
        "model.to(device)\n",
        "\n",
        "# 옵티마이저: Adam (학습률 0.001)\n",
        "# Adam은 학습률을 자동으로 조정하는 효율적인 최적화 알고리즘\n",
        "# optimizer = optim.AdamW(\n",
        "#     model.parameters(),\n",
        "#     lr=0.0005,\n",
        "#     betas=(0.9, 0.98),      # Standard for Transformers\n",
        "#     eps=1e-9,\n",
        "#     weight_decay=0.01       # Proper weight decay\n",
        "# )\n",
        "\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=0.0005,          # 0.0005 → 0.0003\n",
        "    betas=(0.9, 0.98),\n",
        "    eps=1e-9,\n",
        "    weight_decay=0.01    # 0.01 → 0.1\n",
        ")\n",
        "\n",
        "# 손실 함수: Cross Entropy Loss\n",
        "# ignore_index: 패딩 토큰은 손실 계산에서 제외\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=vocab.stoi['<pad>'])\n",
        "\n",
        "# 그래디언트 클리핑 값 (그래디언트 폭발 방지)\n",
        "CLIP = 1.0\n",
        "\n",
        "# 학습 에폭 수\n",
        "N_EPOCHS = 200\n",
        "\n",
        "# Early Stopping 설정\n",
        "best_valid_loss = float('inf')  # 최고 검증 손실 초기화\n",
        "patience = 5  # 성능 개선이 없으면 3 에폭 후 조기 종료\n",
        "patience_counter = 0  # 카운터 초기화\n",
        "\n",
        "print(f\"모델 파라미터 수: {sum(p.numel() for p in model.parameters()):,}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b771c946",
      "metadata": {
        "id": "b771c946"
      },
      "source": [
        "## Step 5: Model Training and Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "id": "b49BeGvQKUU_",
      "metadata": {
        "id": "b49BeGvQKUU_"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \"\"\"\n",
        "    한 에폭 동안 모델 학습\n",
        "\n",
        "    Args:\n",
        "        model: Transformer 모델\n",
        "        iterator: 학습 데이터 로더\n",
        "        optimizer: 옵티마이저 (Adam)\n",
        "        criterion: 손실 함수 (CrossEntropyLoss)\n",
        "        clip: 그래디언트 클리핑 값\n",
        "\n",
        "    Returns:\n",
        "        평균 손실\n",
        "    \"\"\"\n",
        "    # 학습 모드로 설정 (드롭아웃 활성화)\n",
        "    model.train()\n",
        "\n",
        "    epoch_loss = 0  # 에폭 총 손실\n",
        "\n",
        "    # 모든 배치에 대해 반복\n",
        "    for batch in iterator:\n",
        "        # 1. 데이터를 디바이스로 이동\n",
        "        src = batch['SRC'].to(device)  # 소스 (질문)\n",
        "        trg = batch['TRG'].to(device)  # 타겟 (답변)\n",
        "\n",
        "        # 2. 그래디언트 초기화 (이전 배치의 그래디언트 제거)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 3. Forward pass: 모델 예측\n",
        "        # output: (batch_size, tgt_len, vocab_size)\n",
        "        output, _, _ = model(src, trg)\n",
        "\n",
        "        # 4. 손실 계산\n",
        "        # output[:, :-1]: 마지막 토큰 제외 (다음 토큰 예측용)\n",
        "        # trg[:, 1:]: 첫 토큰 제외 (BOS 제거, 실제 정답)\n",
        "        # Teacher Forcing: 실제 정답을 입력으로 사용\n",
        "\n",
        "        # Reshape for loss calculation\n",
        "        # (batch_size, tgt_len-1, vocab_size) → (batch_size * (tgt_len-1), vocab_size)\n",
        "        output = output[:, :-1, :].reshape(-1, output.shape[-1])\n",
        "\n",
        "        # (batch_size, tgt_len-1) → (batch_size * (tgt_len-1))\n",
        "        trg = trg[:, 1:].reshape(-1)\n",
        "\n",
        "        # Cross Entropy Loss 계산\n",
        "        loss = criterion(output, trg)\n",
        "\n",
        "        # 5. Backward pass: 그래디언트 계산\n",
        "        loss.backward()\n",
        "\n",
        "        # 6. 그래디언트 클리핑 (그래디언트 폭발 방지)\n",
        "        # 그래디언트의 노름이 clip을 넘지 않도록 조정\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "\n",
        "        # 7. 파라미터 업데이트\n",
        "        optimizer.step()\n",
        "\n",
        "        # 배치 손실 누적\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    # 평균 손실 반환\n",
        "    return epoch_loss / len(iterator)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \"\"\"\n",
        "    모델 평가 (검증/테스트)\n",
        "\n",
        "    학습과 유사하지만:\n",
        "    - 그래디언트 계산 안 함 (torch.no_grad)\n",
        "    - 파라미터 업데이트 안 함\n",
        "    - 드롭아웃 비활성화 (model.eval)\n",
        "\n",
        "    Args:\n",
        "        model: 평가할 모델\n",
        "        iterator: 검증/테스트 데이터 로더\n",
        "        criterion: 손실 함수\n",
        "\n",
        "    Returns:\n",
        "        평균 손실\n",
        "    \"\"\"\n",
        "    # 평가 모드로 설정 (드롭아웃 비활성화)\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0\n",
        "\n",
        "    # 그래디언트 계산 비활성화 (메모리 절약, 속도 향상)\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            # 데이터 로드\n",
        "            src = batch['SRC'].to(device)\n",
        "            trg = batch['TRG'].to(device)\n",
        "\n",
        "            # Forward pass (그래디언트 계산 안 함)\n",
        "            output, _, _ = model(src, trg)\n",
        "\n",
        "            # 손실 계산 (학습과 동일)\n",
        "            output = output[:, :-1, :].reshape(-1, output.shape[-1])\n",
        "            trg = trg[:, 1:].reshape(-1)\n",
        "            loss = criterion(output, trg)\n",
        "\n",
        "            # 손실 누적\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    # 평균 손실 반환\n",
        "    return epoch_loss / len(iterator)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a86002a8",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "id": "LWfu3n8CKUU_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWfu3n8CKUU_",
        "outputId": "410e4563-32f7-4b8f-8016-6500b8f63555"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Start Model Training\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:   1%|          | 1/100 [01:04<1:45:48, 64.12s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 1] Model Saved! Valid Loss: 3.205\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:   2%|▏         | 2/100 [01:54<1:31:45, 56.18s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 2] Model Saved! Valid Loss: 2.898\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:   3%|▎         | 3/100 [02:40<1:23:08, 51.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 3] Model Saved! Valid Loss: 2.707\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:   4%|▍         | 4/100 [03:33<1:23:30, 52.19s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 4] Model Saved! Valid Loss: 2.570\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:   5%|▌         | 5/100 [04:24<1:21:40, 51.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 5] Model Saved! Valid Loss: 2.476\n",
            "\n",
            "Epoch: 05\n",
            "\tTrain Loss: 2.428\n",
            "\tValidation Loss: 2.476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:   6%|▌         | 6/100 [05:05<1:15:20, 48.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 6] Model Saved! Valid Loss: 2.410\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:   7%|▋         | 7/100 [06:01<1:18:29, 50.64s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 7] Model Saved! Valid Loss: 2.340\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:   8%|▊         | 8/100 [07:20<1:31:14, 59.51s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 8] Model Saved! Valid Loss: 2.292\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:   9%|▉         | 9/100 [08:04<1:23:16, 54.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 9] Model Saved! Valid Loss: 2.249\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:  10%|█         | 10/100 [08:41<1:13:48, 49.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 10] Model Saved! Valid Loss: 2.213\n",
            "\n",
            "Epoch: 10\n",
            "\tTrain Loss: 1.852\n",
            "\tValidation Loss: 2.213\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:  11%|█         | 11/100 [09:17<1:06:57, 45.14s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 11] Model Saved! Valid Loss: 2.184\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:  12%|█▏        | 12/100 [09:55<1:03:17, 43.15s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 12] Model Saved! Valid Loss: 2.153\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:  13%|█▎        | 13/100 [10:51<1:08:05, 46.97s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 13] Model Saved! Valid Loss: 2.152\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:  14%|█▍        | 14/100 [11:57<1:15:39, 52.79s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 14] Model Saved! Valid Loss: 2.130\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:  15%|█▌        | 15/100 [12:51<1:14:58, 52.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 15] No Improvement (1/5)\n",
            "\n",
            "Epoch: 15\n",
            "\tTrain Loss: 1.397\n",
            "\tValidation Loss: 2.132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:  16%|█▌        | 16/100 [13:32<1:09:09, 49.39s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 16] Model Saved! Valid Loss: 2.122\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:  17%|█▋        | 17/100 [14:30<1:12:12, 52.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 17] No Improvement (1/5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:  18%|█▊        | 18/100 [15:37<1:17:20, 56.59s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 18] No Improvement (2/5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:  19%|█▉        | 19/100 [16:26<1:13:23, 54.36s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 19] No Improvement (3/5)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:  20%|██        | 20/100 [17:16<1:10:41, 53.02s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 20] No Improvement (4/5)\n",
            "\n",
            "Epoch: 20\n",
            "\tTrain Loss: 1.060\n",
            "\tValidation Loss: 2.133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training in Progress:  20%|██        | 20/100 [18:14<1:12:56, 54.70s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Epoch 21] No Improvement (5/5)\n",
            "\n",
            "Early Stopping! (최고 Valid Loss: 2.122)\n",
            "\n",
            "==================================================\n",
            "학습 완료!\n",
            "==================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ===== 모델 학습 시작 =====\n",
        "\n",
        "# 학습 하이퍼파라미터\n",
        "N_EPOCHS = 100  # 최대 에폭 수\n",
        "CLIP = 1  # 그래디언트 클리핑\n",
        "best_valid_loss = float('inf')  # 최고 검증 손실 (초기값: 무한대)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(\"Start Model Training\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Early Stopping 설정\n",
        "patience = 5  # 성능 개선 없으면 5 에폭 후 종료\n",
        "patience_counter = 0  # 카운터 초기화\n",
        "\n",
        "# 학습 루프\n",
        "for epoch in tqdm(range(N_EPOCHS), desc=\"Training in Progress\"):\n",
        "    # 1. 학습\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
        "\n",
        "    # 2. 검증\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "\n",
        "    # 3. Early Stopping 체크\n",
        "    if valid_loss < best_valid_loss:\n",
        "        # 검증 손실이 개선됨\n",
        "        best_valid_loss = valid_loss  # 최고 기록 갱신\n",
        "        patience_counter = 0  # 카운터 리셋\n",
        "\n",
        "        # 최고 성능 모델 저장\n",
        "        torch.save(model.state_dict(), 'best_model.pt')\n",
        "        print(f'\\n[Epoch {epoch+1}] Model Saved! Valid Loss: {valid_loss:.3f}')\n",
        "    else:\n",
        "        # 검증 손실이 개선되지 않음\n",
        "        patience_counter += 1  # 카운터 증가\n",
        "        print(f'\\n[Epoch {epoch+1}] No Improvement ({patience_counter}/{patience})')\n",
        "\n",
        "        # Patience 초과 시 조기 종료\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"\\nEarly Stopping! (최고 Valid Loss: {best_valid_loss:.3f})\")\n",
        "            break\n",
        "\n",
        "    # 4. 학습 상태 출력\n",
        "    if (epoch + 1) % 5 == 0:  # 5 에폭마다 출력\n",
        "        print(f'\\nEpoch: {epoch+1:02}')\n",
        "        print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "        print(f'\\tValidation Loss: {valid_loss:.3f}')\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"학습 완료!\")\n",
        "print(\"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "id": "gUxdiw62KUU_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUxdiw62KUU_",
        "outputId": "fbd1f0b9-92bc-4731-d2e2-5f99e1e78ec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "테스트 손실: 2.099\n",
            "테스트 Perplexity: 8.157\n"
          ]
        }
      ],
      "source": [
        "# ===== 테스트 세트 최종 평가 =====\n",
        "\n",
        "# 저장된 최고 모델 로드\n",
        "model.load_state_dict(torch.load('best_model.pt'))\n",
        "\n",
        "# 테스트 세트 평가\n",
        "test_loss = evaluate(model, test_iterator, criterion)\n",
        "\n",
        "print(f\"\\n테스트 손실: {test_loss:.3f}\")\n",
        "print(f\"테스트 Perplexity: {np.exp(test_loss):.3f}\")  # Perplexity: exp(loss)\n",
        "# Perplexity: 모델의 불확실성 지표 (낮을수록 좋음)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8d4299d",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "id": "kzPFdbv7KUU_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzPFdbv7KUU_",
        "outputId": "7b918b19-f8ab-4d31-e846-ce952f3e8bfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==================================================\n",
            "모델 추론 예제\n",
            "==================================================\n",
            "\n",
            "질문: 짝사랑이랑 연애하고 싶다\n",
            "답변: 짝사랑이 그렇게 만드네요.\n",
            "\n",
            "질문: 오늘 날씨가 안좋아!\n",
            "답변: 마스크 쓰고 좋겠네요.\n",
            "\n",
            "질문: 뭐 하고 있나요 하고 메시지 보내고 싶어\n",
            "답변: 어떤 결정이었을텐데 맘고생 많았어요.\n",
            "\n",
            "질문: 고기 먹고 싶어\n",
            "답변: 저도 밥 먹고 싶어요.\n",
            "\n",
            "질문: 내가 좋아하는 거 알았는데도 나를 대하는게 변함이 없어.\n",
            "답변: 관심을 가지세요.\n",
            "\n",
            "질문: 내가 좋아하는 걸 티냈는데 그 사람은 반응이 없어.\n",
            "답변: 서로의 의사가 존중된 것이라면 좋겠어요.\n",
            "\n",
            "질문: 요즘 너무 외로워서 힘들어.\n",
            "답변: 위험하네요.\n"
          ]
        }
      ],
      "source": [
        "# ===== 답변 생성 함수 (추론) =====\n",
        "\n",
        "def generate_response(model, question, vocab, max_length=40):\n",
        "    \"\"\"\n",
        "    주어진 질문에 대해 모델이 답변을 생성\n",
        "\n",
        "    생성 방식: Greedy Decoding\n",
        "    - 각 스텝에서 가장 확률이 높은 토큰 선택\n",
        "    - 빠르지만 최적이 아닐 수 있음\n",
        "\n",
        "    Args:\n",
        "        model: 학습된 Transformer 모델\n",
        "        question: 입력 질문 (문자열)\n",
        "        vocab: 어휘 사전\n",
        "        max_length: 최대 생성 길이\n",
        "\n",
        "    Returns:\n",
        "        생성된 답변 (문자열)\n",
        "    \"\"\"\n",
        "    # 평가 모드\n",
        "    model.eval()\n",
        "\n",
        "    # 질문 전처리 및 토큰화\n",
        "    question = preprocess_sentence(question)  # 텍스트 정제\n",
        "    src_ids = [vocab.BOS_ID] + vocab.encode(question) + [vocab.EOS_ID]  # [BOS] + tokens + [EOS]\n",
        "    src = torch.tensor(src_ids, dtype=torch.long).unsqueeze(0).to(device)  # (1, src_len)\n",
        "\n",
        "    # 그래디언트 계산 비활성화\n",
        "    with torch.no_grad():\n",
        "        # 1. 인코더: 질문 인코딩\n",
        "        enc_mask = (src == vocab.stoi['<pad>'])  # 패딩 마스크\n",
        "        encoder_output, _ = model.encoder(src, attention_mask=enc_mask)\n",
        "\n",
        "        # 2. 디코더: 답변 생성 (자동 회귀)\n",
        "        # 초기 입력: [BOS] 토큰\n",
        "        trg_ids = [vocab.BOS_ID]\n",
        "\n",
        "        # 최대 길이까지 또는 [EOS] 생성까지 반복\n",
        "        for _ in range(max_length):\n",
        "            # 현재까지 생성된 타겟 시퀀스\n",
        "            trg = torch.tensor(trg_ids, dtype=torch.long).unsqueeze(0).to(device)  # (1, cur_len)\n",
        "\n",
        "            # 인과 마스크 생성 (미래 토큰 마스킹)\n",
        "            tgt_len = trg.size(1)\n",
        "            dec_mask = torch.triu(\n",
        "                torch.ones(tgt_len, tgt_len, dtype=torch.bool, device=device),\n",
        "                diagonal=1\n",
        "            )\n",
        "\n",
        "            # 디코더 forward\n",
        "            decoder_output, _ = model.decoder(\n",
        "                trg, encoder_output,\n",
        "                encoder_attention_mask=enc_mask,\n",
        "                decoder_causal_mask=dec_mask\n",
        "            )\n",
        "\n",
        "            # 최종 출력 레이어\n",
        "            # (1, cur_len, emb_dim) → (1, cur_len, vocab_size)\n",
        "            output = model.prediction_head(decoder_output)\n",
        "\n",
        "            # 마지막 토큰의 예측만 사용\n",
        "            # (1, vocab_size)\n",
        "            next_token_logits = output[:, -1, :]\n",
        "\n",
        "            # 가장 높은 확률의 토큰 선택 (Greedy)\n",
        "            next_token = next_token_logits.argmax(dim=-1).item()\n",
        "\n",
        "            # 생성된 토큰을 시퀀스에 추가\n",
        "            trg_ids.append(next_token)\n",
        "\n",
        "            # [EOS] 토큰이 생성되면 종료\n",
        "            if next_token == vocab.EOS_ID:\n",
        "                break\n",
        "\n",
        "    # 3. 토큰 ID를 문자열로 디코딩\n",
        "    # BOS, EOS 제거\n",
        "    response = vocab.decode(trg_ids[1:-1])  # [BOS]와 [EOS] 제외\n",
        "\n",
        "    return response\n",
        "\n",
        "\n",
        "# ===== 예제 추론 =====\n",
        "\n",
        "# 테스트 질문들\n",
        "test_questions = [\n",
        "    \"짝사랑이랑 연애하고 싶다\",\n",
        "    \"오늘 날씨가 안좋아!\",\n",
        "    \"뭐 하고 있나요 하고 메시지 보내고 싶어\",\n",
        "    \"고기 먹고 싶어\",\n",
        "    \"내가 좋아하는 거 알았는데도 나를 대하는게 변함이 없어.\",\n",
        "    \"내가 좋아하는 걸 티냈는데 그 사람은 반응이 없어.\",\n",
        "    \"요즘 너무 외로워서 힘들어.\",\n",
        "]\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"모델 추론 예제\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 각 질문에 대해 답변 생성\n",
        "for question in test_questions:\n",
        "    response = generate_response(model, question, vocab)\n",
        "    print(f\"\\n질문: {question}\")\n",
        "    print(f\"답변: {response}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "id": "pJ24e9ozmwiE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJ24e9ozmwiE",
        "outputId": "3772d80e-c8a8-4dc5-a6c4-0dfa351fc4c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Q (from file): 감 말랭이 먹어야지\n",
            "A (model reply): 맛있게 드세요.\n",
            "\n",
            "Q (from file): 감기 같애\n",
            "A (model reply): 병원가세요.\n",
            "\n",
            "Q (from file): 감기 걸린 것 같아\n",
            "A (model reply): 이젠 그럴 때가 있죠.\n",
            "\n",
            "Q (from file): 감기 기운이 있어\n",
            "A (model reply): 운동을 해보는 건 어떨까요.\n",
            "\n",
            "Q (from file): 감기 들 거 같애\n",
            "A (model reply): 병원가세요.\n",
            "\n",
            "Q (from file): 감기가 오려나\n",
            "A (model reply): 병원가세요.\n",
            "\n",
            "Q (from file): 감기약이 없어\n",
            "A (model reply): 병원가세요.\n",
            "\n",
            "Q (from file): 감기인거 같애\n",
            "A (model reply): 병원가세요.\n",
            "\n",
            "Q (from file): 감미로운 목소리 좋아\n",
            "A (model reply): 스트레스가 심하겠네요.\n",
            "\n",
            "Q (from file): 감정이 쓰레기통처럼 엉망진창이야\n",
            "A (model reply): 상처받았으면 인연이라면 상처가 필요하겠네요.\n",
            "\n",
            "Q (from file): 감정컨트롤을 못하겠어\n",
            "A (model reply): 스스로 존중하고 중하고 중하세요.\n",
            "\n",
            "Q (from file): 감정컨트롤이 안돼\n",
            "A (model reply): 스스로 존중하고 중하고 중하세요.\n",
            "\n",
            "Q (from file): 감히 나를 무시하는 애가 있어\n",
            "A (model reply): 상처가 될 거예요.\n",
            "\n",
            "Q (from file): 갑자기 나쁜 생각이 막 들더라\n",
            "A (model reply): 상처받지 않았으면 좋겠어요.\n",
            "\n",
            "Q (from file): 갑자기 눈물 나\n",
            "A (model reply): 고마워질 거예요.\n",
            "\n",
            "Q (from file): 갑자기 물어봐서 당황했어\n",
            "A (model reply): 갑작스럽겠네요.\n",
            "\n",
            "Q (from file): 갑자기 불편한 사이가 된 거 같아\n",
            "A (model reply): 제가 있잖아요.\n",
            "\n",
            "Q (from file): 강렬한 첫인상 남겨야 하는데\n",
            "A (model reply): 상처가 예뻐지 않는 게 좋겠어요.\n",
            "\n",
            "Q (from file): 강아지 키우고 싶어\n",
            "A (model reply): 주변에 주물어보세요.\n",
            "\n",
            "Q (from file): 강아지 키우고 싶은데 역시 안돼겠지\n",
            "A (model reply): 따뜻하게 물어보세요.\n",
            "\n",
            "Q (from file): 강아지 키울 수 있을까\n",
            "A (model reply): 주변 사람들에게 물어보세요.\n",
            "\n",
            "Q (from file): 강아지 키울까\n",
            "A (model reply): 책임질 수 있을 거예요.\n",
            "\n",
            "Q (from file): 강원도 가서 살까?\n",
            "A (model reply): 아예 적게 먹고 싶네요.\n",
            "\n",
            "Q (from file): 같이 게임하자고 해도 되나?\n",
            "A (model reply): 용기를 내서 고백해보세요.\n",
            "\n",
            "Q (from file): 같이 놀러갈 친구가 없어\n",
            "A (model reply): 웃으면서 복이 오세요.\n",
            "\n",
            "Q (from file): 같이 먹었는데 나만 살찐 거 같아\n",
            "A (model reply): 연인은 알기 힘들어요.\n",
            "\n",
            "Q (from file): 같이 수영장 가기로 했어\n",
            "A (model reply): 즐거운 추천해요.\n",
            "\n",
            "Q (from file): 같이 있으면 힘든데 붙잡고 싶어\n",
            "A (model reply): 질질 끌지 마세요.\n",
            "\n",
            "Q (from file): 같이 피씨방 가자고 해볼까?\n",
            "A (model reply): 용기내서 말해보세요.\n",
            "\n",
            "Q (from file): 같이 할 수 있는 취미 생활 뭐 있을까\n",
            "A (model reply): 함께 충분한 대화를 나눠보는게 좋겠어요.\n",
            "\n",
            "==================================================\n",
            "CSV 파일 테스트 완료.\n",
            "==================================================\n"
          ]
        }
      ],
      "source": [
        "#추가 실험\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "questions_from_file = df['Q'].tolist()\n",
        "questions_to_test = questions_from_file[50:80]\n",
        "for question in questions_to_test:\n",
        "    response = generate_response(model, question, vocab)\n",
        "    print(f\"\\nQ (from file): {question}\")\n",
        "    print(f\"A (model reply): {response}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"CSV 파일 테스트 완료.\")\n",
        "print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rdOqIzedeQqM",
      "metadata": {
        "id": "rdOqIzedeQqM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "experiment",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.24"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
