{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1071dcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import sentencepiece as spm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "592d54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/wansookim/Downloads/code_implementation/transformer_project_submit/data/ChatbotData.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6badf5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Step 2: 데이터 전처리하기\n",
    "# ============================================\n",
    "def load_data(file_path):\n",
    "    \"\"\"\n",
    "    CSV 파일에서 챗봇 데이터를 로드합니다.\n",
    "    \n",
    "    Args:\n",
    "        file_path: CSV 파일 경로\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: 로드된 데이터프레임\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"데이터 로딩 중...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # CSV 파일 읽기\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    print(f\"전체 데이터 수: {len(df)}\")\n",
    "    print(f\"\\n데이터 샘플:\")\n",
    "    print(df.head())\n",
    "    print(f\"\\n컬럼: {df.columns.tolist()}\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "70498e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \"\"\"\n",
    "    단일 문장을 전처리합니다.\n",
    "    \n",
    "    전처리 과정:\n",
    "    1. 소문자 변환 제거 (한국어는 대소문자 구분이 없음)\n",
    "    2. 특수문자 처리 (일부는 유지, 일부는 제거)\n",
    "    3. 중복 공백 제거\n",
    "    4. 문장 앞뒤 공백 제거\n",
    "    \n",
    "    Args:\n",
    "        sentence: 전처리할 문장\n",
    "    \n",
    "    Returns:\n",
    "        str: 전처리된 문장\n",
    "    \"\"\"\n",
    "    # None이나 NaN 값 처리\n",
    "    if pd.isna(sentence) or sentence is None:\n",
    "        return \"\"\n",
    "    \n",
    "    # 문자열로 변환\n",
    "    sentence = str(sentence)\n",
    "    \n",
    "    # 1. 한국어, 영어, 숫자, 기본 구두점만 남기기\n",
    "    # ㄱ-ㅎ: 한글 자음\n",
    "    # ㅏ-ㅣ: 한글 모음  \n",
    "    # 가-힣: 완성형 한글\n",
    "    # a-zA-Z: 영어\n",
    "    # 0-9: 숫자\n",
    "    # \\s: 공백\n",
    "    # .,!?~: 기본 구두점\n",
    "    sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9\\s.,!?~ㅠㅜ]', ' ', sentence)\n",
    "    \n",
    "    # 2. ㅠ, ㅜ 같은 감정 표현 자음/모음은 제거하거나 유지 (여기서는 유지)\n",
    "    # 필요시 제거: sentence = re.sub(r'[ㅠㅜ]+', '', sentence)\n",
    "    \n",
    "    # 3. 여러 개의 공백을 하나로 통일\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    \n",
    "    # 4. 문장 앞뒤 공백 제거\n",
    "    sentence = sentence.strip()\n",
    "    \n",
    "    # 5. 연속된 특수문자 제거 (예: !!!!! -> !)\n",
    "    sentence = re.sub(r'([!?.])\\1+', r'\\1', sentence)\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5285858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(df):\n",
    "    \"\"\"\n",
    "    DataFrame을 질문-답변 쌍으로 변환하고 전처리합니다.\n",
    "    \n",
    "    Args:\n",
    "        df: 원본 데이터프레임\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (questions, answers) - 전처리된 질문과 답변 리스트\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"데이터 전처리 중...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 질문(Q)과 답변(A) 컬럼 추출\n",
    "    questions = df['Q'].tolist()\n",
    "    answers = df['A'].tolist()\n",
    "    \n",
    "    # 각 문장 전처리\n",
    "    preprocessed_questions = []\n",
    "    preprocessed_answers = []\n",
    "    \n",
    "    for i, (q, a) in enumerate(zip(questions, answers)):\n",
    "        # 전처리 수행\n",
    "        clean_q = preprocess_sentence(q)\n",
    "        clean_a = preprocess_sentence(a)\n",
    "        \n",
    "        # 빈 문장이 아닌 경우만 추가\n",
    "        if clean_q and clean_a:\n",
    "            preprocessed_questions.append(clean_q)\n",
    "            preprocessed_answers.append(clean_a)\n",
    "        \n",
    "        # 진행상황 출력 (1000개마다)\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"전처리 진행: {i + 1}/{len(questions)}\")\n",
    "    \n",
    "    print(f\"\\n전처리 완료!\")\n",
    "    print(f\"유효한 데이터 쌍: {len(preprocessed_questions)}\")\n",
    "    print(f\"\\n전처리 예시:\")\n",
    "    for i in range(min(5, len(preprocessed_questions))):\n",
    "        print(f\"Q: {preprocessed_questions[i]}\")\n",
    "        print(f\"A: {preprocessed_answers[i]}\")\n",
    "        print()\n",
    "    \n",
    "    return preprocessed_questions, preprocessed_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4baf67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_processed_data(questions, answers, output_dir='./data'):\n",
    "    \"\"\"\n",
    "    전처리된 데이터를 파일로 저장합니다.\n",
    "    \n",
    "    Args:\n",
    "        questions: 질문 리스트\n",
    "        answers: 답변 리스트\n",
    "        output_dir: 출력 디렉토리\n",
    "    \"\"\"\n",
    "    # 출력 디렉토리 생성\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 질문과 답변을 각각 파일로 저장\n",
    "    questions_path = os.path.join(output_dir, 'questions.txt')\n",
    "    answers_path = os.path.join(output_dir, 'answers.txt')\n",
    "    \n",
    "    with open(questions_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(questions))\n",
    "    \n",
    "    with open(answers_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(answers))\n",
    "    \n",
    "    print(f\"\\n전처리된 데이터 저장 완료:\")\n",
    "    print(f\"  - 질문: {questions_path}\")\n",
    "    print(f\"  - 답변: {answers_path}\")\n",
    "    \n",
    "    # SentencePiece 학습을 위한 통합 파일 생성\n",
    "    all_sentences_path = os.path.join(output_dir, 'all_sentences.txt')\n",
    "    with open(all_sentences_path, 'w', encoding='utf-8') as f:\n",
    "        # 질문과 답변 모두 포함\n",
    "        f.write('\\n'.join(questions + answers))\n",
    "    \n",
    "    print(f\"  - 통합 문장: {all_sentences_path}\")\n",
    "    \n",
    "    return questions_path, answers_path, all_sentences_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7cf5c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# Step 3: SentencePiece 사용하기\n",
    "# ============================================\n",
    "\n",
    "def train_sentencepiece(input_file, model_prefix, vocab_size=8000):\n",
    "    \"\"\"\n",
    "    SentencePiece 모델을 학습합니다.\n",
    "    \n",
    "    SentencePiece는 서브워드 단위로 토크나이징을 수행하는 비지도 학습 기반 토크나이저입니다.\n",
    "    형태소 분석기 없이도 효과적으로 한국어를 토크나이징할 수 있습니다.\n",
    "    \n",
    "    장점:\n",
    "    - 언어에 독립적 (Language-agnostic)\n",
    "    - Out-of-vocabulary(OOV) 문제 해결\n",
    "    - 서브워드 단위로 분리하여 의미 있는 단위 학습\n",
    "    \n",
    "    Args:\n",
    "        input_file: 학습할 텍스트 파일 경로\n",
    "        model_prefix: 저장될 모델 이름 (prefix)\n",
    "        vocab_size: 어휘 사전 크기 (기본값: 8000)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (모델 파일 경로, 어휘 사전 파일 경로)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"SentencePiece 모델 학습 시작\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # SentencePiece 학습 파라미터 설정\n",
    "    # --input: 학습할 텍스트 파일\n",
    "    # --model_prefix: 저장될 모델 이름\n",
    "    # --vocab_size: 어휘 사전 크기 (서브워드 개수)\n",
    "    # --model_type: 모델 타입 (unigram, bpe, char, word 중 선택)\n",
    "    #               - unigram: 확률 기반, 가장 일반적\n",
    "    #               - bpe: Byte Pair Encoding\n",
    "    # --max_sentence_length: 최대 문장 길이\n",
    "    # --pad_id, --unk_id, --bos_id, --eos_id: 특수 토큰 ID 설정\n",
    "    # --user_defined_symbols: 사용자 정의 특수 토큰\n",
    "    \n",
    "    templates = '--input={} \\\n",
    "                 --model_prefix={} \\\n",
    "                 --vocab_size={} \\\n",
    "                 --model_type=unigram \\\n",
    "                 --max_sentence_length=999999 \\\n",
    "                 --pad_id=0 \\\n",
    "                 --unk_id=1 \\\n",
    "                 --bos_id=2 \\\n",
    "                 --eos_id=3 \\\n",
    "                 --user_defined_symbols=[SEP],[CLS],[MASK]'\n",
    "    \n",
    "    # 학습 명령어 생성\n",
    "    cmd = templates.format(input_file, model_prefix, vocab_size)\n",
    "    \n",
    "    print(f\"학습 설정:\")\n",
    "    print(f\"  - 입력 파일: {input_file}\")\n",
    "    print(f\"  - 모델 이름: {model_prefix}\")\n",
    "    print(f\"  - 어휘 크기: {vocab_size}\")\n",
    "    print(f\"  - 모델 타입: unigram\")\n",
    "    print(f\"\\n학습 시작... (시간이 소요될 수 있습니다)\")\n",
    "    \n",
    "    # SentencePiece 학습 실행\n",
    "    spm.SentencePieceTrainer.Train(cmd)\n",
    "    \n",
    "    model_file = f\"{model_prefix}.model\"\n",
    "    vocab_file = f\"{model_prefix}.vocab\"\n",
    "    \n",
    "    print(f\"\\n학습 완료!\")\n",
    "    print(f\"  - 모델 파일: {model_file}\")\n",
    "    print(f\"  - 어휘 파일: {vocab_file}\")\n",
    "    \n",
    "    return model_file, vocab_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dba268f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sentencepiece(model_file, test_sentences):\n",
    "    \"\"\"\n",
    "    학습된 SentencePiece 모델을 테스트합니다.\n",
    "    \n",
    "    Args:\n",
    "        model_file: 학습된 모델 파일 경로\n",
    "        test_sentences: 테스트할 문장 리스트\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"SentencePiece 토크나이저 테스트\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # SentencePiece 프로세서 로드\n",
    "    sp = spm.SentencePieceProcessor()\n",
    "    sp.Load(model_file)\n",
    "    \n",
    "    print(f\"어휘 사전 크기: {sp.GetPieceSize()}\")\n",
    "    print(f\"특수 토큰:\")\n",
    "    print(f\"  - PAD: {sp.IdToPiece(0)} (ID: 0)\")\n",
    "    print(f\"  - UNK: {sp.IdToPiece(1)} (ID: 1)\")\n",
    "    print(f\"  - BOS: {sp.IdToPiece(2)} (ID: 2)\")\n",
    "    print(f\"  - EOS: {sp.IdToPiece(3)} (ID: 3)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"토크나이징 예시\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for sentence in test_sentences:\n",
    "        # 1. 문장을 서브워드로 분리\n",
    "        pieces = sp.EncodeAsPieces(sentence)\n",
    "        \n",
    "        # 2. 문장을 ID로 변환\n",
    "        ids = sp.EncodeAsIds(sentence)\n",
    "        \n",
    "        # 3. ID를 다시 문장으로 변환 (디코딩)\n",
    "        decoded = sp.DecodeIds(ids)\n",
    "        \n",
    "        print(f\"\\n원본 문장: {sentence}\")\n",
    "        print(f\"서브워드:  {pieces}\")\n",
    "        print(f\"ID:        {ids}\")\n",
    "        print(f\"디코딩:    {decoded}\")\n",
    "        print(f\"토큰 수:   {len(pieces)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2a0f5f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_dataset(questions, answers, sp, max_length=40):\n",
    "    \"\"\"\n",
    "    질문과 답변을 SentencePiece로 인코딩합니다.\n",
    "    \n",
    "    Args:\n",
    "        questions: 질문 리스트\n",
    "        answers: 답변 리스트\n",
    "        sp: SentencePiece 프로세서\n",
    "        max_length: 최대 시퀀스 길이\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (인코딩된 질문, 인코딩된 답변)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"데이터셋 인코딩 중...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    encoded_questions = []\n",
    "    encoded_answers = []\n",
    "    \n",
    "    # BOS(Beginning of Sentence), EOS(End of Sentence) 토큰 ID\n",
    "    BOS_ID = 2\n",
    "    EOS_ID = 3\n",
    "    \n",
    "    for i, (q, a) in enumerate(zip(questions, answers)):\n",
    "        # 질문 인코딩: [BOS] + 질문 + [EOS]\n",
    "        q_ids = [BOS_ID] + sp.EncodeAsIds(q) + [EOS_ID]\n",
    "        \n",
    "        # 답변 인코딩: [BOS] + 답변 + [EOS]\n",
    "        a_ids = [BOS_ID] + sp.EncodeAsIds(a) + [EOS_ID]\n",
    "        \n",
    "        # 최대 길이 체크 (너무 긴 문장 제외)\n",
    "        if len(q_ids) <= max_length and len(a_ids) <= max_length:\n",
    "            encoded_questions.append(q_ids)\n",
    "            encoded_answers.append(a_ids)\n",
    "        \n",
    "        # 진행상황 출력\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"인코딩 진행: {i + 1}/{len(questions)}\")\n",
    "    \n",
    "    print(f\"\\n인코딩 완료!\")\n",
    "    print(f\"유효한 시퀀스 쌍: {len(encoded_questions)}\")\n",
    "    print(f\"최대 질문 길이: {max(len(q) for q in encoded_questions)}\")\n",
    "    print(f\"최대 답변 길이: {max(len(a) for a in encoded_answers)}\")\n",
    "    print(f\"평균 질문 길이: {sum(len(q) for q in encoded_questions) / len(encoded_questions):.2f}\")\n",
    "    print(f\"평균 답변 길이: {sum(len(a) for a in encoded_answers) / len(encoded_answers):.2f}\")\n",
    "    \n",
    "    return encoded_questions, encoded_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3ac911f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "데이터 전처리 중...\n",
      "==================================================\n",
      "전처리 진행: 1000/11823\n",
      "전처리 진행: 2000/11823\n",
      "전처리 진행: 3000/11823\n",
      "전처리 진행: 4000/11823\n",
      "전처리 진행: 5000/11823\n",
      "전처리 진행: 6000/11823\n",
      "전처리 진행: 7000/11823\n",
      "전처리 진행: 8000/11823\n",
      "전처리 진행: 9000/11823\n",
      "전처리 진행: 10000/11823\n",
      "전처리 진행: 11000/11823\n",
      "\n",
      "전처리 완료!\n",
      "유효한 데이터 쌍: 11823\n",
      "\n",
      "전처리 예시:\n",
      "Q: 12시 땡!\n",
      "A: 하루가 또 가네요.\n",
      "\n",
      "Q: 1지망 학교 떨어졌어\n",
      "A: 위로해 드립니다.\n",
      "\n",
      "Q: 3박4일 놀러가고 싶다\n",
      "A: 여행은 언제나 좋죠.\n",
      "\n",
      "Q: 3박4일 정도 놀러가고 싶다\n",
      "A: 여행은 언제나 좋죠.\n",
      "\n",
      "Q: PPL 심하네\n",
      "A: 눈살이 찌푸려지죠.\n",
      "\n",
      "\n",
      "전처리된 데이터 저장 완료:\n",
      "  - 질문: ./data/questions.txt\n",
      "  - 답변: ./data/answers.txt\n",
      "  - 통합 문장: ./data/all_sentences.txt\n",
      "\n",
      "==================================================\n",
      "SentencePiece 모델 학습 시작\n",
      "==================================================\n",
      "학습 설정:\n",
      "  - 입력 파일: ./data/all_sentences.txt\n",
      "  - 모델 이름: ./data/korean_chatbot_sp\n",
      "  - 어휘 크기: 8000\n",
      "  - 모델 타입: unigram\n",
      "\n",
      "학습 시작... (시간이 소요될 수 있습니다)\n",
      "\n",
      "학습 완료!\n",
      "  - 모델 파일: ./data/korean_chatbot_sp.model\n",
      "  - 어휘 파일: ./data/korean_chatbot_sp.vocab\n",
      "\n",
      "==================================================\n",
      "SentencePiece 토크나이저 테스트\n",
      "==================================================\n",
      "어휘 사전 크기: 8000\n",
      "특수 토큰:\n",
      "  - PAD: <pad> (ID: 0)\n",
      "  - UNK: <unk> (ID: 1)\n",
      "  - BOS: <s> (ID: 2)\n",
      "  - EOS: </s> (ID: 3)\n",
      "\n",
      "==================================================\n",
      "토크나이징 예시\n",
      "==================================================\n",
      "\n",
      "원본 문장: 안녕하세요\n",
      "서브워드:  ['▁안녕하세요']\n",
      "ID:        [3162]\n",
      "디코딩:    안녕하세요\n",
      "토큰 수:   1\n",
      "\n",
      "원본 문장: 오늘 날씨가 정말 좋네요\n",
      "서브워드:  ['▁오늘', '▁날씨', '가', '▁정말', '▁좋', '네요']\n",
      "ID:        [76, 542, 12, 104, 883, 26]\n",
      "디코딩:    오늘 날씨가 정말 좋네요\n",
      "토큰 수:   6\n",
      "\n",
      "원본 문장: 챗봇 만들기 재미있어요\n",
      "서브워드:  ['▁', '챗', '봇', '▁만들기', '▁재미있어', '요']\n",
      "ID:        [8, 1, 7656, 3750, 2102, 9]\n",
      "디코딩:     ⁇ 봇 만들기 재미있어요\n",
      "토큰 수:   6\n",
      "\n",
      "원본 문장: 12시 땡!\n",
      "서브워드:  ['▁12', '시', '▁', '땡', '!']\n",
      "ID:        [4294, 572, 8, 7824, 61]\n",
      "디코딩:    12시 땡!\n",
      "토큰 수:   5\n",
      "\n",
      "원본 문장: 하루가 또 가네요.\n",
      "서브워드:  ['▁하루', '가', '▁또', '▁가', '네요', '.']\n",
      "ID:        [256, 12, 106, 86, 26, 7]\n",
      "디코딩:    하루가 또 가네요.\n",
      "토큰 수:   6\n",
      "\n",
      "==================================================\n",
      "데이터셋 인코딩 중...\n",
      "==================================================\n",
      "인코딩 진행: 1000/11823\n",
      "인코딩 진행: 2000/11823\n",
      "인코딩 진행: 3000/11823\n",
      "인코딩 진행: 4000/11823\n",
      "인코딩 진행: 5000/11823\n",
      "인코딩 진행: 6000/11823\n",
      "인코딩 진행: 7000/11823\n",
      "인코딩 진행: 8000/11823\n",
      "인코딩 진행: 9000/11823\n",
      "인코딩 진행: 10000/11823\n",
      "인코딩 진행: 11000/11823\n",
      "\n",
      "인코딩 완료!\n",
      "유효한 시퀀스 쌍: 11823\n",
      "최대 질문 길이: 26\n",
      "최대 답변 길이: 37\n",
      "평균 질문 길이: 7.59\n",
      "평균 답변 길이: 8.86\n",
      "\n",
      "==================================================\n",
      "데이터 분리 완료\n",
      "==================================================\n",
      "학습 데이터: 10640쌍\n",
      "검증 데이터: 1183쌍\n",
      "\n",
      "인코딩된 데이터 저장 완료!\n",
      "  - ./data/train_questions.npy\n",
      "  - ./data/train_answers.npy\n",
      "  - ./data/val_questions.npy\n",
      "  - ./data/val_answers.npy\n",
      "\n",
      "==================================================\n",
      "전처리 및 토크나이저 학습 완료!\n",
      "==================================================\n",
      "\n",
      "다음 단계: 트랜스포머 모델 구성 및 학습\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=./data/all_sentences.txt                  --model_prefix=./data/korean_chatbot_sp                  --vocab_size=8000                  --model_type=unigram                  --max_sentence_length=999999                  --pad_id=0                  --unk_id=1                  --bos_id=2                  --eos_id=3                  --user_defined_symbols=[SEP],[CLS],[MASK]\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./data/all_sentences.txt\n",
      "  input_format: \n",
      "  model_prefix: ./data/korean_chatbot_sp\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 999999\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: [SEP]\n",
      "  user_defined_symbols: [CLS]\n",
      "  user_defined_symbols: [MASK]\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 1\n",
      "  bos_id: 2\n",
      "  eos_id: 3\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: ./data/all_sentences.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 23646 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [SEP]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [CLS]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [MASK]\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=353346\n",
      "trainer_interface.cc(552) LOG(INFO) Done: 99.9505% characters are covered.\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=1081\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=0.999505\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 23646 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=162511\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 18854 seed sentencepieces\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 23646\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 21767\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 21767 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=10901 obj=13.2232 num_tokens=46216 num_tokens/piece=4.23961\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9585 obj=12.117 num_tokens=46316 num_tokens/piece=4.83213\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=8798 obj=12.2706 num_tokens=47162 num_tokens/piece=5.36054\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=8783 obj=12.2463 num_tokens=47198 num_tokens/piece=5.37379\n",
      "trainer_interface.cc(689) LOG(INFO) Saving model: ./data/korean_chatbot_sp.model\n",
      "trainer_interface.cc(701) LOG(INFO) Saving vocabs: ./data/korean_chatbot_sp.vocab\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/wansookim/Downloads/code_implementation/transformer_project_submit/data/ChatbotData.csv')\n",
    "\n",
    "# ============================================\n",
    "# 메인 실행 코드\n",
    "# ============================================\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    전체 전처리 및 토크나이저 학습 파이프라인\n",
    "    \"\"\"\n",
    "    # 1. 데이터 로드\n",
    "    df = data\n",
    "    # 2. 데이터 전처리\n",
    "    questions, answers = create_dataset(df)\n",
    "    \n",
    "    # 3. 전처리된 데이터 저장\n",
    "    questions_path, answers_path, all_sentences_path = save_processed_data(\n",
    "        questions, answers, output_dir='./data'\n",
    "    )\n",
    "    \n",
    "    # 4. SentencePiece 모델 학습\n",
    "    model_file, vocab_file = train_sentencepiece(\n",
    "        input_file=all_sentences_path,\n",
    "        model_prefix='./data/korean_chatbot_sp',\n",
    "        vocab_size=8000\n",
    "    )\n",
    "    \n",
    "    # 5. SentencePiece 모델 테스트\n",
    "    test_sentences = [\n",
    "        \"안녕하세요\",\n",
    "        \"오늘 날씨가 정말 좋네요\",\n",
    "        \"챗봇 만들기 재미있어요\",\n",
    "        questions[0],\n",
    "        answers[0]\n",
    "    ]\n",
    "    test_sentencepiece(model_file, test_sentences)\n",
    "    \n",
    "    # 6. 전체 데이터셋 인코딩\n",
    "    sp = spm.SentencePieceProcessor()\n",
    "    sp.Load(model_file)\n",
    "    \n",
    "    encoded_questions, encoded_answers = encode_dataset(\n",
    "        questions, answers, sp, max_length=40\n",
    "    )\n",
    "    \n",
    "    # 7. 학습/검증 데이터 분리\n",
    "    train_q, val_q, train_a, val_a = train_test_split(\n",
    "        encoded_questions, encoded_answers, \n",
    "        test_size=0.1, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"데이터 분리 완료\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"학습 데이터: {len(train_q)}쌍\")\n",
    "    print(f\"검증 데이터: {len(val_q)}쌍\")\n",
    "    \n",
    "    # 8. 인코딩된 데이터 저장 (numpy 배열로)\n",
    "    np.save('./data/train_questions.npy', np.array(train_q, dtype=object))\n",
    "    np.save('./data/train_answers.npy', np.array(train_a, dtype=object))\n",
    "    np.save('./data/val_questions.npy', np.array(val_q, dtype=object))\n",
    "    np.save('./data/val_answers.npy', np.array(val_a, dtype=object))\n",
    "    \n",
    "    print(\"\\n인코딩된 데이터 저장 완료!\")\n",
    "    print(\"  - ./data/train_questions.npy\")\n",
    "    print(\"  - ./data/train_answers.npy\")\n",
    "    print(\"  - ./data/val_questions.npy\")\n",
    "    print(\"  - ./data/val_answers.npy\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"전처리 및 토크나이저 학습 완료!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"\\n다음 단계: 트랜스포머 모델 구성 및 학습\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "da57fabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multi-headed attention from 'Attention Is All You Need' paper\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        emb_dim,\n",
    "        num_heads,\n",
    "        dropout=0.0,\n",
    "        bias=False,\n",
    "        encoder_decoder_attention=False,  # otherwise self_attention\n",
    "        causal = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.head_dim = emb_dim // num_heads\n",
    "        assert self.head_dim * num_heads == self.emb_dim, \"emb_dim must be divisible by num_heads\"\n",
    "\n",
    "        self.encoder_decoder_attention = encoder_decoder_attention\n",
    "        self.causal = causal\n",
    "        self.q_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "        self.k_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "        self.v_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "        self.out_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "\n",
    "\n",
    "    def transpose_for_scores(self, x):\n",
    "        # (batch_size, seq_len, emb_dim) -> (batch_size, num_heads, seq_len, head_dim) for multi-headed attention\n",
    "        new_x_shape = x.size()[:-1] + (\n",
    "            self.num_heads,\n",
    "            self.head_dim,\n",
    "        )\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "        # This is equivalent to\n",
    "        # return x.transpose(1,2)\n",
    "\n",
    "\n",
    "    def scaled_dot_product(self,\n",
    "                           query: torch.Tensor,\n",
    "                           key: torch.Tensor,\n",
    "                           value: torch.Tensor,\n",
    "                           attention_mask: torch.BoolTensor):\n",
    "\n",
    "        attn_weights = torch.matmul(query, key.transpose(-1, -2)) / math.sqrt(self.emb_dim) # QK^T/sqrt(d)\n",
    "\n",
    "        if attention_mask is not None:\n",
    "            attn_weights = attn_weights.masked_fill(attention_mask.unsqueeze(1), float(\"-inf\"))\n",
    "\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)  # softmax(QK^T/sqrt(d))\n",
    "        attn_probs = F.dropout(attn_weights, p=self.dropout, training=self.training)\n",
    "        attn_output = torch.matmul(attn_probs, value) # softmax(QK^T/sqrt(d))V\n",
    "\n",
    "        return attn_output, attn_probs\n",
    "\n",
    "\n",
    "    def MultiHead_scaled_dot_product(self,\n",
    "                       query: torch.Tensor,\n",
    "                       key: torch.Tensor,\n",
    "                       value: torch.Tensor,\n",
    "                       attention_mask: torch.BoolTensor):\n",
    "\n",
    "        attn_weights = torch.matmul(query, key.transpose(-1, -2)) / math.sqrt(self.head_dim) # QK^T/sqrt(d)\n",
    "\n",
    "        # Attention mask\n",
    "        if attention_mask is not None:\n",
    "            if self.causal:\n",
    "              # (seq_len x seq_len)\n",
    "                attn_weights = attn_weights.masked_fill(attention_mask.unsqueeze(0).unsqueeze(1), float(\"-inf\"))\n",
    "            else:\n",
    "              # (batch_size x seq_len)\n",
    "                attn_weights = attn_weights.masked_fill(attention_mask.unsqueeze(1).unsqueeze(2), float(\"-inf\"))\n",
    "\n",
    "\n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)  # softmax(QK^T/sqrt(d))\n",
    "        attn_probs = F.dropout(attn_weights, p=self.dropout, training=self.training)\n",
    "\n",
    "        attn_output = torch.matmul(attn_probs, value) # softmax(QK^T/sqrt(d))V\n",
    "        attn_output = attn_output.permute(0, 2, 1, 3).contiguous()\n",
    "        concat_attn_output_shape = attn_output.size()[:-2] + (self.emb_dim,)\n",
    "        attn_output = attn_output.view(*concat_attn_output_shape)\n",
    "        attn_output = self.out_proj(attn_output)\n",
    "\n",
    "        return attn_output, attn_weights\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        query: torch.Tensor,\n",
    "        key: torch.Tensor,\n",
    "        attention_mask: torch.Tensor = None,\n",
    "        ):\n",
    "\n",
    "        q = self.q_proj(query)\n",
    "        # Enc-Dec attention\n",
    "        if self.encoder_decoder_attention:\n",
    "            k = self.k_proj(key)\n",
    "            v = self.v_proj(key)\n",
    "        # Self attention\n",
    "        else:\n",
    "            k = self.k_proj(query)\n",
    "            v = self.v_proj(query)\n",
    "\n",
    "        q = self.transpose_for_scores(q)\n",
    "        k = self.transpose_for_scores(k)\n",
    "        v = self.transpose_for_scores(v)\n",
    "\n",
    "        attn_output, attn_weights = self.MultiHead_scaled_dot_product(q,k,v,attention_mask)\n",
    "        return attn_output, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9dfcccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, emb_dim: int, d_ff: int, dropout: float = 0.1):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        self.w_1 = nn.Linear(emb_dim, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, emb_dim)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.activation(self.w_1(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.w_2(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x + residual # residual connection for preventing gradient vanishing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7cdaac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Since Transformer contains no recurrence and no convolution,\n",
    "# in order for the model to make use of the order of the sequence,\n",
    "# we must inject some information about the relative or absolute position of the tokens in the sequence.\n",
    "# To this end, we add “positional encodings” to the input embeddings at the bottoms of the encoder and decoder stacks.\n",
    "# There are many choices of positional encodings, learned and fixed\n",
    "\n",
    "class SinusoidalPositionalEmbedding(nn.Embedding):\n",
    "\n",
    "    def __init__(self, num_positions, embedding_dim, padding_idx=None):\n",
    "        super().__init__(num_positions, embedding_dim) # torch.nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.weight = self._init_weight(self.weight) # self.weight => nn.Embedding(num_positions, embedding_dim).weight\n",
    "\n",
    "    @staticmethod\n",
    "    def _init_weight(out: nn.Parameter):\n",
    "        n_pos, embed_dim = out.shape\n",
    "        pe = nn.Parameter(torch.zeros(out.shape))\n",
    "        for pos in range(n_pos):\n",
    "            for i in range(0, embed_dim, 2):\n",
    "                pe[pos, i].data.copy_( torch.tensor( np.sin(pos / (10000 ** ( i / embed_dim)))) )\n",
    "                pe[pos, i + 1].data.copy_( torch.tensor( np.cos(pos / (10000 ** ((i + 1) / embed_dim)))) )\n",
    "        pe.detach_()\n",
    "\n",
    "        return pe\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, input_ids):\n",
    "      bsz, seq_len = input_ids.shape[:2]\n",
    "      positions = torch.arange(seq_len, dtype=torch.long, device=self.weight.device)\n",
    "      return super().forward(positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "213af6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.emb_dim = config.emb_dim\n",
    "        self.ffn_dim = config.ffn_dim\n",
    "        self.self_attn = MultiHeadAttention(\n",
    "            emb_dim=self.emb_dim,\n",
    "            num_heads=config.attention_heads,\n",
    "            dropout=config.attention_dropout)\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(self.emb_dim)\n",
    "        self.dropout = config.dropout\n",
    "        self.activation_fn = nn.ReLU()\n",
    "        self.PositionWiseFeedForward = PositionWiseFeedForward(self.emb_dim, self.ffn_dim, config.dropout)\n",
    "        self.final_layer_norm = nn.LayerNorm(self.emb_dim)\n",
    "\n",
    "    def forward(self, x, encoder_padding_mask):\n",
    "\n",
    "        residual = x\n",
    "        x, attn_weights = self.self_attn(query=x, key=x, attention_mask=encoder_padding_mask)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = residual + x\n",
    "        x = self.self_attn_layer_norm(x)\n",
    "        x = self.PositionWiseFeedForward(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "        if torch.isinf(x).any() or torch.isnan(x).any():\n",
    "            clamp_value = torch.finfo(x.dtype).max - 1000\n",
    "            x = torch.clamp(x, min=-clamp_value, max=clamp_value)\n",
    "        return x, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "398346a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, config, embed_tokens):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = config.dropout\n",
    "\n",
    "        emb_dim = embed_tokens.embedding_dim\n",
    "        self.padding_idx = embed_tokens.padding_idx\n",
    "        self.max_source_positions = config.max_position_embeddings\n",
    "\n",
    "        self.embed_tokens = embed_tokens\n",
    "        self.embed_positions = SinusoidalPositionalEmbedding(\n",
    "                config.max_position_embeddings, config.emb_dim, self.padding_idx\n",
    "            )\n",
    "\n",
    "        self.layers = nn.ModuleList([EncoderLayer(config) for _ in range(config.encoder_layers)])\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "\n",
    "        inputs_embeds = self.embed_tokens(input_ids)\n",
    "        embed_pos = self.embed_positions(input_ids)\n",
    "        x = inputs_embeds + embed_pos\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        self_attn_scores = []\n",
    "        for encoder_layer in self.layers:\n",
    "            x, attn = encoder_layer(x, attention_mask)\n",
    "            self_attn_scores.append(attn.detach())\n",
    "\n",
    "        return x, self_attn_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "23c60022",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.emb_dim = config.emb_dim\n",
    "        self.ffn_dim = config.ffn_dim\n",
    "        self.self_attn = MultiHeadAttention(\n",
    "            emb_dim=self.emb_dim,\n",
    "            num_heads=config.attention_heads,\n",
    "            dropout=config.attention_dropout,\n",
    "            causal=True,\n",
    "        )\n",
    "        self.dropout = config.dropout\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(self.emb_dim)\n",
    "        self.encoder_attn = MultiHeadAttention(\n",
    "            emb_dim=self.emb_dim,\n",
    "            num_heads=config.attention_heads,\n",
    "            dropout=config.attention_dropout,\n",
    "            encoder_decoder_attention=True,\n",
    "        )\n",
    "        self.encoder_attn_layer_norm = nn.LayerNorm(self.emb_dim)\n",
    "        self.PositionWiseFeedForward = PositionWiseFeedForward(self.emb_dim, self.ffn_dim, config.dropout)\n",
    "        self.final_layer_norm = nn.LayerNorm(self.emb_dim)\n",
    "\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x,\n",
    "        encoder_hidden_states,\n",
    "        encoder_attention_mask=None,\n",
    "        causal_mask=None,\n",
    "    ):\n",
    "        residual = x\n",
    "        # Self Attention\n",
    "        x, self_attn_weights = self.self_attn(\n",
    "            query=x,\n",
    "            key=x, # adds keys to layer state\n",
    "            attention_mask=causal_mask,\n",
    "        )\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = residual + x\n",
    "        x = self.self_attn_layer_norm(x)\n",
    "\n",
    "        # Cross-Attention Block\n",
    "        residual = x\n",
    "        x, cross_attn_weights = self.encoder_attn(\n",
    "            query=x,\n",
    "            key=encoder_hidden_states,\n",
    "            attention_mask=encoder_attention_mask,\n",
    "        )\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = residual + x\n",
    "        x = self.encoder_attn_layer_norm(x)\n",
    "\n",
    "        # Fully Connected\n",
    "        x = self.PositionWiseFeedForward(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "\n",
    "        return (\n",
    "            x,\n",
    "            self_attn_weights,\n",
    "            cross_attn_weights,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "94f18bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, config, embed_tokens: nn.Embedding):\n",
    "        super().__init__()\n",
    "        self.dropout = config.dropout\n",
    "        self.padding_idx = embed_tokens.padding_idx\n",
    "        self.max_target_positions = config.max_position_embeddings\n",
    "        self.embed_tokens = embed_tokens\n",
    "        self.embed_positions = SinusoidalPositionalEmbedding(\n",
    "            config.max_position_embeddings, config.emb_dim, self.padding_idx\n",
    "        )\n",
    "        self.layers = nn.ModuleList([DecoderLayer(config) for _ in range(config.decoder_layers)])  # type: List[DecoderLayer]\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids,\n",
    "        encoder_hidden_states,\n",
    "        encoder_attention_mask,\n",
    "        decoder_causal_mask,\n",
    "    ):\n",
    "\n",
    "        # embed positions\n",
    "        positions = self.embed_positions(input_ids)\n",
    "        x = self.embed_tokens(input_ids)\n",
    "        x += positions\n",
    "\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        # decoder layers\n",
    "        cross_attention_scores = []\n",
    "        for idx, decoder_layer in enumerate(self.layers):\n",
    "            x, layer_self_attn, layer_cross_attn = decoder_layer(\n",
    "                x,\n",
    "                encoder_hidden_states,\n",
    "                encoder_attention_mask=encoder_attention_mask,\n",
    "                causal_mask=decoder_causal_mask,\n",
    "            )\n",
    "            cross_attention_scores.append(layer_cross_attn.detach())\n",
    "\n",
    "        return x, cross_attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ead7ffc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "데이터 전처리 중...\n",
      "==================================================\n",
      "전처리 진행: 1000/11823\n",
      "전처리 진행: 2000/11823\n",
      "전처리 진행: 3000/11823\n",
      "전처리 진행: 4000/11823\n",
      "전처리 진행: 5000/11823\n",
      "전처리 진행: 6000/11823\n",
      "전처리 진행: 7000/11823\n",
      "전처리 진행: 8000/11823\n",
      "전처리 진행: 9000/11823\n",
      "전처리 진행: 10000/11823\n",
      "전처리 진행: 11000/11823\n",
      "\n",
      "전처리 완료!\n",
      "유효한 데이터 쌍: 11823\n",
      "\n",
      "전처리 예시:\n",
      "Q: 12시 땡!\n",
      "A: 하루가 또 가네요.\n",
      "\n",
      "Q: 1지망 학교 떨어졌어\n",
      "A: 위로해 드립니다.\n",
      "\n",
      "Q: 3박4일 놀러가고 싶다\n",
      "A: 여행은 언제나 좋죠.\n",
      "\n",
      "Q: 3박4일 정도 놀러가고 싶다\n",
      "A: 여행은 언제나 좋죠.\n",
      "\n",
      "Q: PPL 심하네\n",
      "A: 눈살이 찌푸려지죠.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "questions, answers = create_dataset(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "80090cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Vocab 크기: 8,000\n",
      "✓ 학습: 9,458쌍\n",
      "✓ Device: mps\n"
     ]
    }
   ],
   "source": [
    "# === SentencePieceVocab 클래스 ===\n",
    "import sentencepiece as spm\n",
    "\n",
    "class SentencePieceVocab:\n",
    "    def __init__(self, sp_model_path):\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.Load(sp_model_path)\n",
    "        self.PAD_ID = 0\n",
    "        self.UNK_ID = 1\n",
    "        self.BOS_ID = 2\n",
    "        self.EOS_ID = 3\n",
    "        self.stoi = {'<pad>': 0, '<unk>': 1, '<s>': 2, '</s>': 3}\n",
    "        self.itos = [self.sp.IdToPiece(i) for i in range(self.sp.GetPieceSize())]\n",
    "    \n",
    "    def encode(self, sentence):\n",
    "        return self.sp.EncodeAsIds(sentence)\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        return self.sp.DecodeIds([i for i in ids if i not in [0, 2, 3]])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.sp.GetPieceSize()\n",
    "\n",
    "\n",
    "# === ChatbotDataset 클래스 ===\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ChatbotDataset(Dataset):\n",
    "    def __init__(self, questions, answers, vocab, max_length=40):\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        self.vocab = vocab\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        q = self.questions[idx]\n",
    "        a = self.answers[idx]\n",
    "        src = [self.vocab.BOS_ID] + self.vocab.encode(q) + [self.vocab.EOS_ID]\n",
    "        trg = [self.vocab.BOS_ID] + self.vocab.encode(a) + [self.vocab.EOS_ID]\n",
    "        return {\n",
    "            'SRC': torch.tensor(src[:self.max_length], dtype=torch.long),\n",
    "            'TRG': torch.tensor(trg[:self.max_length], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "# === Collate 함수 ===\n",
    "def collate_fn(batch, pad_idx=0):\n",
    "    src_batch = [item['SRC'] for item in batch]\n",
    "    trg_batch = [item['TRG'] for item in batch]\n",
    "    src_max = max(len(s) for s in src_batch)\n",
    "    trg_max = max(len(t) for t in trg_batch)\n",
    "    \n",
    "    src_padded = [torch.cat([s, torch.tensor([pad_idx]*(src_max-len(s)))]) \n",
    "                  for s in src_batch]\n",
    "    trg_padded = [torch.cat([t, torch.tensor([pad_idx]*(trg_max-len(t)))]) \n",
    "                  for t in trg_batch]\n",
    "    \n",
    "    return {'SRC': torch.stack(src_padded), 'TRG': torch.stack(trg_padded)}\n",
    "\n",
    "\n",
    "# === 실제 객체 생성 ⭐ ===\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Vocab 생성\n",
    "SRC_vocab = SentencePieceVocab('./data/korean_chatbot_sp.model')\n",
    "TRG_vocab = SRC_vocab\n",
    "\n",
    "# 데이터 분할\n",
    "train_q, temp_q, train_a, temp_a = train_test_split(\n",
    "    questions, answers, test_size=0.2, random_state=42\n",
    ")\n",
    "val_q, test_q, val_a, test_a = train_test_split(\n",
    "    temp_q, temp_a, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Dataset\n",
    "train_dataset = ChatbotDataset(train_q, train_a, SRC_vocab, 40)\n",
    "val_dataset = ChatbotDataset(val_q, val_a, SRC_vocab, 40)\n",
    "test_dataset = ChatbotDataset(test_q, test_a, SRC_vocab, 40)\n",
    "\n",
    "# DataLoader\n",
    "train_iterator = DataLoader(train_dataset, batch_size=32, shuffle=True,\n",
    "                            collate_fn=lambda b: collate_fn(b, SRC_vocab.PAD_ID))\n",
    "valid_iterator = DataLoader(val_dataset, batch_size=32, shuffle=False,\n",
    "                            collate_fn=lambda b: collate_fn(b, SRC_vocab.PAD_ID))\n",
    "test_iterator = DataLoader(test_dataset, batch_size=32, shuffle=False,\n",
    "                           collate_fn=lambda b: collate_fn(b, SRC_vocab.PAD_ID))\n",
    "\n",
    "# device 설정\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "\n",
    "print(f\"✓ Vocab 크기: {len(SRC_vocab):,}\")\n",
    "print(f\"✓ 학습: {len(train_q):,}쌍\")\n",
    "print(f\"✓ Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fff54197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Assuming 'Encoder' and 'Decoder' are defined elsewhere in your code\n",
    "# If not, you'll need to define these classes as well\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, SRC_vocab, TRG_vocab, config):\n",
    "        super().__init__()\n",
    "\n",
    "        self.SRC_vocab = SRC_vocab\n",
    "        self.TRG_vocab = TRG_vocab\n",
    "\n",
    "        self.enc_embedding = nn.Embedding(len(SRC_vocab.itos), config.emb_dim, padding_idx=SRC_vocab.stoi['<pad>'])\n",
    "        self.dec_embedding = nn.Embedding(len(TRG_vocab.itos), config.emb_dim, padding_idx=TRG_vocab.stoi['<pad>'])\n",
    "\n",
    "        self.encoder = Encoder(config, self.enc_embedding)\n",
    "        self.decoder = Decoder(config, self.dec_embedding)\n",
    "\n",
    "        self.prediction_head = nn.Linear(config.emb_dim, len(TRG_vocab.itos))\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def generate_mask(self, src, trg):\n",
    "        # Mask encoder attention to ignore padding\n",
    "        enc_attention_mask = src.eq(self.SRC_vocab.stoi['<pad>']).to(device)\n",
    "        # Mask decoder attention for causality\n",
    "        tmp = torch.ones(trg.size(1), trg.size(1), dtype=torch.bool, device=device)\n",
    "        mask = torch.arange(tmp.size(-1), device=device)\n",
    "        dec_attention_mask = tmp.masked_fill_(mask < (mask + 1).view(tmp.size(-1), 1), False).to(device)\n",
    "\n",
    "        return enc_attention_mask, dec_attention_mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'weight' in name:\n",
    "                    nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "                else:\n",
    "                    nn.init.constant_(param.data, 0)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        enc_attention_mask, dec_causal_mask = self.generate_mask(src, trg)\n",
    "        encoder_output, encoder_attention_scores = self.encoder(\n",
    "            input_ids=src,\n",
    "            attention_mask=enc_attention_mask\n",
    "        )\n",
    "\n",
    "        decoder_output, decoder_attention_scores = self.decoder(\n",
    "            trg,\n",
    "            encoder_output,\n",
    "            encoder_attention_mask=enc_attention_mask,\n",
    "            decoder_causal_mask=dec_causal_mask,\n",
    "        )\n",
    "        decoder_output = self.prediction_head(decoder_output)\n",
    "\n",
    "        return decoder_output, encoder_attention_scores, decoder_attention_scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ab4d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "afded1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easydict\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Create the configuration for the transformer model\n",
    "config = easydict.EasyDict({\n",
    "    \"emb_dim\": 64,\n",
    "    \"ffn_dim\": 256,\n",
    "    \"attention_heads\": 4,\n",
    "    \"attention_dropout\": 0.0,\n",
    "    \"dropout\": 0.2,\n",
    "    \"max_position_embeddings\": 512,\n",
    "    \"encoder_layers\": 3,\n",
    "    \"decoder_layers\": 3,\n",
    "})\n",
    "\n",
    "# Constants for training\n",
    "N_EPOCHS = 100\n",
    "learning_rate = 5e-4\n",
    "CLIP = 1\n",
    "\n",
    "# Updated PAD_IDX to use the new Vocab instance\n",
    "PAD_IDX = SRC_vocab.stoi['<pad>']\n",
    "\n",
    "# Instantiate the model using the new Vocab instances instead of the Fields\n",
    "model = Transformer(SRC_vocab, TRG_vocab, config)\n",
    "model.to(device)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the loss function, ignoring the index of the padding token\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "\n",
    "# Initialize the best validation loss\n",
    "best_valid_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0455ef61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got MPSFloatType instead (while checking arguments for embedding)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 67\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(N_EPOCHS), total\u001b[38;5;241m=\u001b[39mN_EPOCHS):\n\u001b[0;32m---> 67\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCLIP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m evaluate(model, valid_iterator, criterion)\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_loss \u001b[38;5;241m<\u001b[39m best_valid_loss:\n",
      "Cell \u001b[0;32mIn[88], line 23\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Assuming src and trg are already tensorized and padded\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# If not, you should perform those steps here\u001b[39;00m\n\u001b[1;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 23\u001b[0m output, enc_attention_scores, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Flatten the output and target tensors to compute the loss\u001b[39;00m\n\u001b[1;32m     26\u001b[0m output \u001b[38;5;241m=\u001b[39m output[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,:]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/envs/experiment/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/experiment/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[86], line 44\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, trg)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, src, trg):\n\u001b[1;32m     43\u001b[0m     enc_attention_mask, dec_causal_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_mask(src, trg)\n\u001b[0;32m---> 44\u001b[0m     encoder_output, encoder_attention_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menc_attention_mask\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     decoder_output, decoder_attention_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\n\u001b[1;32m     50\u001b[0m         trg,\n\u001b[1;32m     51\u001b[0m         encoder_output,\n\u001b[1;32m     52\u001b[0m         encoder_attention_mask\u001b[38;5;241m=\u001b[39menc_attention_mask,\n\u001b[1;32m     53\u001b[0m         decoder_causal_mask\u001b[38;5;241m=\u001b[39mdec_causal_mask,\n\u001b[1;32m     54\u001b[0m     )\n\u001b[1;32m     55\u001b[0m     decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_head(decoder_output)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/experiment/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/experiment/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[81], line 20\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 20\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     embed_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_positions(input_ids)\n\u001b[1;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m embed_pos\n",
      "File \u001b[0;32m/opt/anaconda3/envs/experiment/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/experiment/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/experiment/lib/python3.9/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/experiment/lib/python3.9/site-packages/torch/nn/functional.py:2264\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2258\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2259\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2260\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected tensor for argument #1 'indices' to have one of the following scalar types: Long, Int; but got MPSFloatType instead (while checking arguments for embedding)"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def train(model: nn.Module,\n",
    "          iterator: DataLoader,\n",
    "          optimizer: optim.Optimizer,\n",
    "          criterion: nn.Module,\n",
    "          clip: float):\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for batch in iterator:\n",
    "        src = batch['SRC'].to(device)\n",
    "        trg = batch['TRG'].to(device)\n",
    "\n",
    "        # Assuming src and trg are already tensorized and padded\n",
    "        # If not, you should perform those steps here\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output, enc_attention_scores, _ = model(src, trg)\n",
    "\n",
    "        # Flatten the output and target tensors to compute the loss\n",
    "        output = output[:,:-1,:].reshape(-1, output.shape[-1])\n",
    "        trg = trg[:,1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "def evaluate(model: nn.Module,\n",
    "             iterator: DataLoader,\n",
    "             criterion: nn.Module):\n",
    "\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            src = batch['SRC'].to(device)\n",
    "            trg = batch['TRG'].to(device)\n",
    "\n",
    "            # Assuming src and trg are already tensorized and padded\n",
    "            # If not, you should perform those steps here\n",
    "\n",
    "            output, attention_score, _ = model(src, trg)\n",
    "\n",
    "            # Flatten the output and target tensors to compute the loss\n",
    "            output = output[:,:-1,:].reshape(-1, output.shape[-1])\n",
    "            trg = trg[:,1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(N_EPOCHS), total=N_EPOCHS):\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "    else: # early stopping condition\n",
    "        break\n",
    "\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')\n",
    "\n",
    "# Evaluation on test set\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9d1c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff43a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
