{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d60a3ffa",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "1071dcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "import sentencepiece as spm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import easydict\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c7115a",
   "metadata": {},
   "source": [
    "## Step 2: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "20c227e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    \"\"\"\n",
    "    Preprocess a single sentence.\n",
    "    - Keep Korean, English, numbers, and basic punctuation\n",
    "    - Remove duplicate spaces and special characters\n",
    "    \"\"\"\n",
    "    if pd.isna(sentence) or sentence is None:\n",
    "        return \"\"\n",
    "    \n",
    "    sentence = str(sentence)\n",
    "    sentence = re.sub(r'[^ㄱ-ㅎㅏ-ㅣ가-힣a-zA-Z0-9\\s.,!?~ㅠㅜ]', ' ', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = re.sub(r'([!?.])\\1+', r'\\1', sentence)\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "\n",
    "def load_and_preprocess_data(file_path):\n",
    "    \"\"\"\n",
    "    Load CSV file and preprocess all question-answer pairs.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"Total data: {len(df)} pairs\")\n",
    "    \n",
    "    # Extract and preprocess\n",
    "    questions = []\n",
    "    answers = []\n",
    "    \n",
    "    for i, (q, a) in enumerate(zip(df['Q'], df['A'])):\n",
    "        clean_q = preprocess_sentence(q)\n",
    "        clean_a = preprocess_sentence(a)\n",
    "        \n",
    "        if clean_q and clean_a:\n",
    "            questions.append(clean_q)\n",
    "            answers.append(clean_a)\n",
    "        \n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"Progress: {i + 1}/{len(df)}\")\n",
    "    \n",
    "    print(f\"\\nValid pairs after preprocessing: {len(questions)}\")\n",
    "    print(\"\\nSample data:\")\n",
    "    for i in range(min(3, len(questions))):\n",
    "        print(f\"Q: {questions[i]}\")\n",
    "        print(f\"A: {answers[i]}\\n\")\n",
    "    \n",
    "    return questions, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "592d54ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Loading and preprocessing data...\n",
      "==================================================\n",
      "Total data: 11823 pairs\n",
      "Progress: 1000/11823\n",
      "Progress: 2000/11823\n",
      "Progress: 3000/11823\n",
      "Progress: 4000/11823\n",
      "Progress: 5000/11823\n",
      "Progress: 6000/11823\n",
      "Progress: 7000/11823\n",
      "Progress: 8000/11823\n",
      "Progress: 9000/11823\n",
      "Progress: 10000/11823\n",
      "Progress: 11000/11823\n",
      "\n",
      "Valid pairs after preprocessing: 11823\n",
      "\n",
      "Sample data:\n",
      "Q: 12시 땡!\n",
      "A: 하루가 또 가네요.\n",
      "\n",
      "Q: 1지망 학교 떨어졌어\n",
      "A: 위로해 드립니다.\n",
      "\n",
      "Q: 3박4일 놀러가고 싶다\n",
      "A: 여행은 언제나 좋죠.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "file_path = '/Users/wansookim/Downloads/code_implementation/transformer_project_submit/data/ChatbotData.csv'\n",
    "questions, answers = load_and_preprocess_data(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dfc612",
   "metadata": {},
   "source": [
    "## Step 3: SentencePiece Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "239ee1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sentencepiece_model(questions, answers, model_prefix='./data/korean_chatbot_sp', vocab_size=8000):\n",
    "    \"\"\"\n",
    "    Train SentencePiece model on question-answer pairs.\n",
    "    \"\"\"\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Training SentencePiece model...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Save all sentences to a temporary file\n",
    "    all_sentences_path = './data/all_sentences.txt'\n",
    "    with open(all_sentences_path, 'w', encoding='utf-8') as f:\n",
    "        f.write('\\n'.join(questions + answers))\n",
    "    \n",
    "    # Train SentencePiece\n",
    "    cmd = f'--input={all_sentences_path} \\\n",
    "           --model_prefix={model_prefix} \\\n",
    "           --vocab_size={vocab_size} \\\n",
    "           --model_type=unigram \\\n",
    "           --max_sentence_length=999999 \\\n",
    "           --pad_id=0 \\\n",
    "           --unk_id=1 \\\n",
    "           --bos_id=2 \\\n",
    "           --eos_id=3 \\\n",
    "           --user_defined_symbols=[SEP],[CLS],[MASK]'\n",
    "    \n",
    "    spm.SentencePieceTrainer.Train(cmd)\n",
    "    \n",
    "    model_file = f\"{model_prefix}.model\"\n",
    "    print(f\"\\nModel saved: {model_file}\")\n",
    "    return model_file\n",
    "\n",
    "\n",
    "class SentencePieceVocab:\n",
    "    \"\"\"Wrapper class for SentencePiece model.\"\"\"\n",
    "    def __init__(self, sp_model_path):\n",
    "        self.sp = spm.SentencePieceProcessor()\n",
    "        self.sp.Load(sp_model_path)\n",
    "        self.PAD_ID = 0\n",
    "        self.UNK_ID = 1\n",
    "        self.BOS_ID = 2\n",
    "        self.EOS_ID = 3\n",
    "        self.stoi = {'<pad>': 0, '<unk>': 1, '<s>': 2, '</s>': 3}\n",
    "        self.itos = [self.sp.IdToPiece(i) for i in range(self.sp.GetPieceSize())]\n",
    "    \n",
    "    def encode(self, sentence):\n",
    "        return self.sp.EncodeAsIds(sentence)\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        return self.sp.DecodeIds([i for i in ids if i not in [0, 2, 3]])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.sp.GetPieceSize()\n",
    "\n",
    "\n",
    "class ChatbotDataset(Dataset):\n",
    "    \"\"\"Dataset class for question-answer pairs.\"\"\"\n",
    "    def __init__(self, questions, answers, vocab, max_length=40):\n",
    "        self.questions = questions\n",
    "        self.answers = answers\n",
    "        self.vocab = vocab\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.questions)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        q = self.questions[idx]\n",
    "        a = self.answers[idx]\n",
    "        src = [self.vocab.BOS_ID] + self.vocab.encode(q) + [self.vocab.EOS_ID]\n",
    "        trg = [self.vocab.BOS_ID] + self.vocab.encode(a) + [self.vocab.EOS_ID]\n",
    "        return {\n",
    "            'SRC': torch.tensor(src[:self.max_length], dtype=torch.long),\n",
    "            'TRG': torch.tensor(trg[:self.max_length], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# torch.tensor([pad_idx]*(src_max-len(s)), dtype=torch.long)\n",
    "\n",
    "def collate_fn(batch, pad_idx=0):\n",
    "    \"\"\"Collate function for DataLoader with padding.\"\"\"\n",
    "    src_batch = [item['SRC'] for item in batch]\n",
    "    trg_batch = [item['TRG'] for item in batch]\n",
    "    src_max = max(len(s) for s in src_batch)\n",
    "    trg_max = max(len(t) for t in trg_batch)\n",
    "    \n",
    "    src_padded = [torch.cat([s, torch.tensor([pad_idx]*(src_max-len(s)), dtype=torch.long)]) \n",
    "                  for s in src_batch]\n",
    "    trg_padded = [torch.cat([t, torch.tensor([pad_idx]*(trg_max-len(t)), dtype=torch.long)]) \n",
    "                  for t in trg_batch]\n",
    "    \n",
    "    return {'SRC': torch.stack(src_padded), 'TRG': torch.stack(trg_padded)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "6badf5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training SentencePiece model...\n",
      "==================================================\n",
      "\n",
      "Model saved: ./data/korean_chatbot_sp.model\n",
      "\n",
      "Vocabulary size: 8,000\n",
      "\n",
      "Test sentence: 12시 땡!\n",
      "Encoded: [4294, 572, 8, 7824, 61]...\n",
      "Decoded: 12시 땡!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(178) LOG(INFO) Running command: --input=./data/all_sentences.txt            --model_prefix=./data/korean_chatbot_sp            --vocab_size=8000            --model_type=unigram            --max_sentence_length=999999            --pad_id=0            --unk_id=1            --bos_id=2            --eos_id=3            --user_defined_symbols=[SEP],[CLS],[MASK]\n",
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: ./data/all_sentences.txt\n",
      "  input_format: \n",
      "  model_prefix: ./data/korean_chatbot_sp\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 999999\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  user_defined_symbols: [SEP]\n",
      "  user_defined_symbols: [CLS]\n",
      "  user_defined_symbols: [MASK]\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 1\n",
      "  bos_id: 2\n",
      "  eos_id: 3\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(355) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(186) LOG(INFO) Loading corpus: ./data/all_sentences.txt\n",
      "trainer_interface.cc(411) LOG(INFO) Loaded all 23646 sentences\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [SEP]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [CLS]\n",
      "trainer_interface.cc(427) LOG(INFO) Adding meta_piece: [MASK]\n",
      "trainer_interface.cc(432) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(541) LOG(INFO) all chars count=353346\n",
      "trainer_interface.cc(552) LOG(INFO) Done: 99.9505% characters are covered.\n",
      "trainer_interface.cc(562) LOG(INFO) Alphabet size=1081\n",
      "trainer_interface.cc(563) LOG(INFO) Final character coverage=0.999505\n",
      "trainer_interface.cc(594) LOG(INFO) Done! preprocessed 23646 sentences.\n",
      "unigram_model_trainer.cc(265) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(269) LOG(INFO) Extracting frequent sub strings... node_num=162511\n",
      "unigram_model_trainer.cc(312) LOG(INFO) Initialized 18854 seed sentencepieces\n",
      "trainer_interface.cc(600) LOG(INFO) Tokenizing input sentences with whitespace: 23646\n",
      "trainer_interface.cc(611) LOG(INFO) Done! 21767\n",
      "unigram_model_trainer.cc(602) LOG(INFO) Using 21767 sentences for EM training\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=10901 obj=13.2232 num_tokens=46216 num_tokens/piece=4.23961\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=9585 obj=12.117 num_tokens=46316 num_tokens/piece=4.83213\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=0 size=8798 obj=12.2706 num_tokens=47162 num_tokens/piece=5.36054\n",
      "unigram_model_trainer.cc(618) LOG(INFO) EM sub_iter=1 size=8783 obj=12.2463 num_tokens=47198 num_tokens/piece=5.37379\n",
      "trainer_interface.cc(689) LOG(INFO) Saving model: ./data/korean_chatbot_sp.model\n",
      "trainer_interface.cc(701) LOG(INFO) Saving vocabs: ./data/korean_chatbot_sp.vocab\n"
     ]
    }
   ],
   "source": [
    "# Train SentencePiece model\n",
    "model_file = train_sentencepiece_model(questions, answers)\n",
    "\n",
    "# Create vocabulary\n",
    "vocab = SentencePieceVocab(model_file)\n",
    "print(f\"\\nVocabulary size: {len(vocab):,}\")\n",
    "\n",
    "# Test tokenization\n",
    "test_sentence = questions[0]\n",
    "encoded = vocab.encode(test_sentence)\n",
    "decoded = vocab.decode(encoded)\n",
    "print(f\"\\nTest sentence: {test_sentence}\")\n",
    "print(f\"Encoded: {encoded[:10]}...\")\n",
    "print(f\"Decoded: {decoded}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "70498e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Data split complete\n",
      "==================================================\n",
      "Train: 9,458 pairs\n",
      "Val: 1,182 pairs\n",
      "Test: 1,183 pairs\n"
     ]
    }
   ],
   "source": [
    "# Split data into train/val/test\n",
    "train_q, temp_q, train_a, temp_a = train_test_split(\n",
    "    questions, answers, test_size=0.2, random_state=42\n",
    ")\n",
    "val_q, test_q, val_a, test_a = train_test_split(\n",
    "    temp_q, temp_a, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ChatbotDataset(train_q, train_a, vocab, max_length=40)\n",
    "val_dataset = ChatbotDataset(val_q, val_a, vocab, max_length=40)\n",
    "test_dataset = ChatbotDataset(test_q, test_a, vocab, max_length=40)\n",
    "\n",
    "# Create dataloaders\n",
    "train_iterator = DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True,\n",
    "    collate_fn=lambda b: collate_fn(b, vocab.PAD_ID)\n",
    ")\n",
    "valid_iterator = DataLoader(\n",
    "    val_dataset, batch_size=32, shuffle=False,\n",
    "    collate_fn=lambda b: collate_fn(b, vocab.PAD_ID)\n",
    ")\n",
    "test_iterator = DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=False,\n",
    "    collate_fn=lambda b: collate_fn(b, vocab.PAD_ID)\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Data split complete\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Train: {len(train_q):,} pairs\")\n",
    "print(f\"Val: {len(val_q):,} pairs\")\n",
    "print(f\"Test: {len(test_q):,} pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95eb9a6",
   "metadata": {},
   "source": [
    "## Step 4: Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "5285858d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\"Multi-headed attention from 'Attention Is All You Need' paper.\"\"\"\n",
    "    \n",
    "    def __init__(self, emb_dim, num_heads, dropout=0.0, bias=False, \n",
    "                 encoder_decoder_attention=False, causal=False):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout = dropout\n",
    "        self.head_dim = emb_dim // num_heads\n",
    "        assert self.head_dim * num_heads == self.emb_dim, \"emb_dim must be divisible by num_heads\"\n",
    "        \n",
    "        self.encoder_decoder_attention = encoder_decoder_attention\n",
    "        self.causal = causal\n",
    "        self.q_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "        self.k_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "        self.v_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "        self.out_proj = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "    \n",
    "    def transpose_for_scores(self, x):\n",
    "        new_x_shape = x.size()[:-1] + (self.num_heads, self.head_dim,)\n",
    "        x = x.view(*new_x_shape)\n",
    "        return x.permute(0, 2, 1, 3)\n",
    "    \n",
    "    def forward(self, query, key, attention_mask=None):\n",
    "        q = self.q_proj(query)\n",
    "        \n",
    "        if self.encoder_decoder_attention:\n",
    "            k = self.k_proj(key)\n",
    "            v = self.v_proj(key)\n",
    "        else:\n",
    "            k = self.k_proj(query)\n",
    "            v = self.v_proj(query)\n",
    "        \n",
    "        q = self.transpose_for_scores(q)\n",
    "        k = self.transpose_for_scores(k)\n",
    "        v = self.transpose_for_scores(v)\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        attn_weights = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(self.head_dim)\n",
    "        \n",
    "        if attention_mask is not None:\n",
    "            if self.causal:\n",
    "                attn_weights = attn_weights.masked_fill(\n",
    "                    attention_mask.unsqueeze(0).unsqueeze(1), float(\"-inf\")\n",
    "                )\n",
    "            else:\n",
    "                attn_weights = attn_weights.masked_fill(\n",
    "                    attention_mask.unsqueeze(1).unsqueeze(2), float(\"-inf\")\n",
    "                )\n",
    "        \n",
    "        attn_weights = F.softmax(attn_weights, dim=-1)\n",
    "        attn_probs = F.dropout(attn_weights, p=self.dropout, training=self.training)\n",
    "        \n",
    "        attn_output = torch.matmul(attn_probs, v)\n",
    "        attn_output = attn_output.permute(0, 2, 1, 3).contiguous()\n",
    "        concat_attn_output_shape = attn_output.size()[:-2] + (self.emb_dim,)\n",
    "        attn_output = attn_output.view(*concat_attn_output_shape)\n",
    "        attn_output = self.out_proj(attn_output)\n",
    "        \n",
    "        return attn_output, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "4baf67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    \"\"\"Position-wise feed-forward network.\"\"\"\n",
    "    \n",
    "    def __init__(self, emb_dim, d_ff, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.w_1 = nn.Linear(emb_dim, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, emb_dim)\n",
    "        self.dropout = dropout\n",
    "        self.activation = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.activation(self.w_1(x))\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.w_2(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        return x + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7cf5c104",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionalEmbedding(nn.Embedding):\n",
    "    \"\"\"Sinusoidal positional embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_positions, embedding_dim, padding_idx=None):\n",
    "        super().__init__(num_positions, embedding_dim)\n",
    "        self._init_weight(self.weight)\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _init_weight(out):\n",
    "        \"\"\"\n",
    "        Initialize the weight tensor with sinusoidal values.\n",
    "        Modifies the tensor in-place using .data to avoid autograd issues.\n",
    "        \"\"\"\n",
    "        n_pos, embed_dim = out.shape\n",
    "        \n",
    "        # Create sinusoidal position encodings\n",
    "        position_enc = torch.zeros(n_pos, embed_dim)\n",
    "        \n",
    "        for pos in range(n_pos):\n",
    "            for i in range(0, embed_dim, 2):\n",
    "                position_enc[pos, i] = math.sin(pos / (10000 ** (i / embed_dim)))\n",
    "                if i + 1 < embed_dim:\n",
    "                    position_enc[pos, i + 1] = math.cos(pos / (10000 ** ((i + 1) / embed_dim)))\n",
    "        \n",
    "        # Copy the values into the parameter's data (in-place, no autograd)\n",
    "        out.data.copy_(position_enc)\n",
    "        \n",
    "        # Make sure gradients are not computed for positional embeddings\n",
    "        out.requires_grad = False\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def forward(self, input_ids):\n",
    "        bsz, seq_len = input_ids.shape[:2]\n",
    "        positions = torch.arange(seq_len, dtype=torch.long, device=self.weight.device)\n",
    "        return super().forward(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "dba268f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"Single encoder layer.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.emb_dim = config.emb_dim\n",
    "        self.self_attn = MultiHeadAttention(\n",
    "            emb_dim=self.emb_dim,\n",
    "            num_heads=config.attention_heads,\n",
    "            dropout=config.attention_dropout\n",
    "        )\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(self.emb_dim)\n",
    "        self.ffn = PositionWiseFeedForward(self.emb_dim, config.ffn_dim, config.dropout)\n",
    "        self.final_layer_norm = nn.LayerNorm(self.emb_dim)\n",
    "        self.dropout = config.dropout\n",
    "    \n",
    "    def forward(self, x, encoder_padding_mask):\n",
    "        residual = x\n",
    "        x, attn_weights = self.self_attn(query=x, key=x, attention_mask=encoder_padding_mask)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = residual + x\n",
    "        x = self.self_attn_layer_norm(x)\n",
    "        x = self.ffn(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "        return x, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "2a0f5f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Transformer encoder.\"\"\"\n",
    "    \n",
    "    def __init__(self, config, embed_tokens):\n",
    "        super().__init__()\n",
    "        self.dropout = config.dropout\n",
    "        self.padding_idx = embed_tokens.padding_idx\n",
    "        self.embed_tokens = embed_tokens\n",
    "        self.embed_positions = SinusoidalPositionalEmbedding(\n",
    "            config.max_position_embeddings, config.emb_dim, self.padding_idx\n",
    "        )\n",
    "        self.layers = nn.ModuleList([EncoderLayer(config) for _ in range(config.encoder_layers)])\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        inputs_embeds = self.embed_tokens(input_ids)\n",
    "        embed_pos = self.embed_positions(input_ids)\n",
    "        x = inputs_embeds + embed_pos\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        self_attn_scores = []\n",
    "        for encoder_layer in self.layers:\n",
    "            x, attn = encoder_layer(x, attention_mask)\n",
    "            self_attn_scores.append(attn.detach())\n",
    "        \n",
    "        return x, self_attn_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "9d523cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"Single decoder layer.\"\"\"\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.emb_dim = config.emb_dim\n",
    "        self.self_attn = MultiHeadAttention(\n",
    "            emb_dim=self.emb_dim,\n",
    "            num_heads=config.attention_heads,\n",
    "            dropout=config.attention_dropout,\n",
    "            causal=True,\n",
    "        )\n",
    "        self.self_attn_layer_norm = nn.LayerNorm(self.emb_dim)\n",
    "        self.encoder_attn = MultiHeadAttention(\n",
    "            emb_dim=self.emb_dim,\n",
    "            num_heads=config.attention_heads,\n",
    "            dropout=config.attention_dropout,\n",
    "            encoder_decoder_attention=True,\n",
    "        )\n",
    "        self.encoder_attn_layer_norm = nn.LayerNorm(self.emb_dim)\n",
    "        self.ffn = PositionWiseFeedForward(self.emb_dim, config.ffn_dim, config.dropout)\n",
    "        self.final_layer_norm = nn.LayerNorm(self.emb_dim)\n",
    "        self.dropout = config.dropout\n",
    "    \n",
    "    def forward(self, x, encoder_hidden_states, encoder_attention_mask=None, causal_mask=None):\n",
    "        # Self attention\n",
    "        residual = x\n",
    "        x, self_attn_weights = self.self_attn(query=x, key=x, attention_mask=causal_mask)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = residual + x\n",
    "        x = self.self_attn_layer_norm(x)\n",
    "        \n",
    "        # Cross attention\n",
    "        residual = x\n",
    "        x, cross_attn_weights = self.encoder_attn(\n",
    "            query=x, key=encoder_hidden_states, attention_mask=encoder_attention_mask\n",
    "        )\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = residual + x\n",
    "        x = self.encoder_attn_layer_norm(x)\n",
    "        \n",
    "        # Feed forward\n",
    "        x = self.ffn(x)\n",
    "        x = self.final_layer_norm(x)\n",
    "        \n",
    "        return x, self_attn_weights, cross_attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "55695dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"Transformer decoder.\"\"\"\n",
    "    \n",
    "    def __init__(self, config, embed_tokens):\n",
    "        super().__init__()\n",
    "        self.dropout = config.dropout\n",
    "        self.padding_idx = embed_tokens.padding_idx\n",
    "        self.embed_tokens = embed_tokens\n",
    "        self.embed_positions = SinusoidalPositionalEmbedding(\n",
    "            config.max_position_embeddings, config.emb_dim, self.padding_idx\n",
    "        )\n",
    "        self.layers = nn.ModuleList([DecoderLayer(config) for _ in range(config.decoder_layers)])\n",
    "    \n",
    "    def forward(self, input_ids, encoder_hidden_states, \n",
    "                encoder_attention_mask=None, decoder_causal_mask=None):\n",
    "        inputs_embeds = self.embed_tokens(input_ids)\n",
    "        embed_pos = self.embed_positions(input_ids)\n",
    "        x = inputs_embeds + embed_pos\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        \n",
    "        self_attn_scores = []\n",
    "        cross_attn_scores = []\n",
    "        for decoder_layer in self.layers:\n",
    "            x, self_attn, cross_attn = decoder_layer(\n",
    "                x, encoder_hidden_states, encoder_attention_mask, decoder_causal_mask\n",
    "            )\n",
    "            self_attn_scores.append(self_attn.detach())\n",
    "            cross_attn_scores.append(cross_attn.detach())\n",
    "        \n",
    "        return x, (self_attn_scores, cross_attn_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4e1fb305",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    \"\"\"Complete Transformer model.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab, config):\n",
    "        super().__init__()\n",
    "        self.vocab = vocab\n",
    "        \n",
    "        # Embeddings\n",
    "        self.enc_embedding = nn.Embedding(\n",
    "            len(vocab.itos), config.emb_dim, padding_idx=vocab.stoi['<pad>']\n",
    "        )\n",
    "        self.dec_embedding = nn.Embedding(\n",
    "            len(vocab.itos), config.emb_dim, padding_idx=vocab.stoi['<pad>']\n",
    "        )\n",
    "        \n",
    "        # Encoder and Decoder\n",
    "        self.encoder = Encoder(config, self.enc_embedding)\n",
    "        self.decoder = Decoder(config, self.dec_embedding)\n",
    "        \n",
    "        # Output layer\n",
    "        self.prediction_head = nn.Linear(config.emb_dim, len(vocab.itos))\n",
    "        \n",
    "        self.init_weights()\n",
    "    \n",
    "    def generate_mask(self, src, trg):\n",
    "        # Encoder padding mask\n",
    "        enc_attention_mask = src.eq(self.vocab.stoi['<pad>']).to(device)\n",
    "        \n",
    "        # Decoder causal mask\n",
    "        tmp = torch.ones(trg.size(1), trg.size(1), dtype=torch.bool, device=device)\n",
    "        mask = torch.arange(tmp.size(-1), device=device)\n",
    "        dec_attention_mask = tmp.masked_fill_(mask < (mask + 1).view(tmp.size(-1), 1), False)\n",
    "        \n",
    "        return enc_attention_mask, dec_attention_mask\n",
    "    \n",
    "    def init_weights(self):\n",
    "        for name, param in self.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                if 'weight' in name:\n",
    "                    nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "                else:\n",
    "                    nn.init.constant_(param.data, 0)\n",
    "    \n",
    "    def forward(self, src, trg):\n",
    "        enc_attention_mask, dec_causal_mask = self.generate_mask(src, trg)\n",
    "        \n",
    "        encoder_output, encoder_attention_scores = self.encoder(\n",
    "            input_ids=src, attention_mask=enc_attention_mask\n",
    "        )\n",
    "        \n",
    "        decoder_output, decoder_attention_scores = self.decoder(\n",
    "            trg, encoder_output,\n",
    "            encoder_attention_mask=enc_attention_mask,\n",
    "            decoder_causal_mask=dec_causal_mask,\n",
    "        )\n",
    "        \n",
    "        decoder_output = self.prediction_head(decoder_output)\n",
    "        \n",
    "        return decoder_output, encoder_attention_scores, decoder_attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "68c3b327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Model initialized\n",
      "==================================================\n",
      "Total parameters: 11,934,528\n",
      "Trainable parameters: 11,672,384\n"
     ]
    }
   ],
   "source": [
    "# Model configuration\n",
    "config = easydict.EasyDict({\n",
    "    \"emb_dim\": 256,\n",
    "    \"ffn_dim\": 1024,\n",
    "    \"attention_heads\": 8,\n",
    "    \"attention_dropout\": 0.1,\n",
    "    \"dropout\": 0.1,\n",
    "    \"max_position_embeddings\": 512,\n",
    "    \"encoder_layers\": 3,\n",
    "    \"decoder_layers\": 3,\n",
    "})\n",
    "\n",
    "# Create model\n",
    "model = Transformer(vocab, config)\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer and loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=vocab.PAD_ID)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Model initialized\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b771c946",
   "metadata": {},
   "source": [
    "## Step 5: Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e042cd7e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "ade0cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    \"\"\"Train the model for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for batch in iterator:\n",
    "        src = batch['SRC'].to(device)\n",
    "        trg = batch['TRG'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output, _, _ = model(src, trg)\n",
    "        \n",
    "        # Calculate loss\n",
    "        output = output[:, :-1, :].reshape(-1, output.shape[-1])\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \"\"\"Evaluate the model.\"\"\"\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            src = batch['SRC'].to(device)\n",
    "            trg = batch['TRG'].to(device)\n",
    "            \n",
    "            output, _, _ = model(src, trg)\n",
    "            \n",
    "            # Calculate loss\n",
    "            output = output[:, :-1, :].reshape(-1, output.shape[-1])\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "    \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "068112bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Training started\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 10/100 [06:16<54:10, 36.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/100\n",
      "Train Loss: 4.058 | Train PPL:  57.830\n",
      "Val Loss: 4.365 | Val PPL:  78.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 20/100 [11:21<39:15, 29.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20/100\n",
      "Train Loss: 3.281 | Train PPL:  26.605\n",
      "Val Loss: 4.028 | Val PPL:  56.138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 30/100 [16:31<34:27, 29.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 30/100\n",
      "Train Loss: 2.683 | Train PPL:  14.623\n",
      "Val Loss: 3.906 | Val PPL:  49.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 40/100 [21:26<29:04, 29.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 40/100\n",
      "Train Loss: 2.237 | Train PPL:   9.369\n",
      "Val Loss: 3.909 | Val PPL:  49.843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 50/100 [26:16<23:44, 28.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 50/100\n",
      "Train Loss: 1.926 | Train PPL:   6.865\n",
      "Val Loss: 3.945 | Val PPL:  51.678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 60/100 [31:24<20:05, 30.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 60/100\n",
      "Train Loss: 1.733 | Train PPL:   5.658\n",
      "Val Loss: 4.055 | Val PPL:  57.701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 70/100 [35:58<13:14, 26.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 70/100\n",
      "Train Loss: 1.596 | Train PPL:   4.931\n",
      "Val Loss: 4.143 | Val PPL:  63.002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 80/100 [40:05<07:50, 23.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 80/100\n",
      "Train Loss: 1.517 | Train PPL:   4.557\n",
      "Val Loss: 4.215 | Val PPL:  67.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 90/100 [43:58<03:50, 23.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 90/100\n",
      "Train Loss: 1.452 | Train PPL:   4.272\n",
      "Val Loss: 4.352 | Val PPL:  77.596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 100/100 [47:35<00:00, 28.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/100\n",
      "Train Loss: 1.412 | Train PPL:   4.103\n",
      "Val Loss: 4.371 | Val PPL:  79.127\n",
      "\n",
      "==================================================\n",
      "Training complete\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training parameters\n",
    "N_EPOCHS = 100\n",
    "CLIP = 1\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"Training started\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(N_EPOCHS), desc=\"Training\"):\n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_iterator, criterion)\n",
    "    \n",
    "    # Early stopping\n",
    "    # if valid_loss < best_valid_loss:\n",
    "    #     best_valid_loss = valid_loss\n",
    "    # else:\n",
    "    #     print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "    #     break\n",
    "    \n",
    "    # Print metrics\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"\\nEpoch {epoch+1}/{N_EPOCHS}\")\n",
    "        print(f\"Train Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}\")\n",
    "        print(f\"Val Loss: {valid_loss:.3f} | Val PPL: {math.exp(valid_loss):7.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Training complete\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "fe486f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Loss: 4.357 | Test PPL:  78.021\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test set\n",
    "test_loss = evaluate(model, test_iterator, criterion)\n",
    "print(f\"\\nTest Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5a08f498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Example Inference\n",
      "==================================================\n",
      "Q: 안녕하세요\n",
      "A: 잘 찾아보세요.\n",
      "\n",
      "Q: 오늘 날씨가 좋네요\n",
      "A: 잘 찾아보세요.\n",
      "\n",
      "Q: 뭐 하고 있어요\n",
      "A: 잘 찾아보세요.\n",
      "\n",
      "Q: 고기 먹고 싶어\n",
      "A: 잘 찾아보세요.\n",
      "\n",
      "Q: 내가 좋아하는 거 알았는데도 나를 대하는게 변함이 없어.\n",
      "A: 잘 찾아보세요.\n",
      "\n",
      "Q: 내가 좋아하는 걸 티냈는데 그 사람은 반응이 없어.\n",
      "A: 잘 찾아보세요.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example inference\n",
    "def generate_response(model, question, vocab, max_length=40):\n",
    "    \"\"\"Generate a response for a given question.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Preprocess and encode\n",
    "    clean_q = preprocess_sentence(question)\n",
    "    src = torch.tensor(\n",
    "        [vocab.BOS_ID] + vocab.encode(clean_q) + [vocab.EOS_ID]\n",
    "    ).unsqueeze(0).to(device)\n",
    "    \n",
    "    # Start with BOS token\n",
    "    trg_indices = [vocab.BOS_ID]\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        trg = torch.LongTensor(trg_indices).unsqueeze(0).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, _, _ = model(src, trg)\n",
    "        \n",
    "        pred_token = output.argmax(2)[:, -1].item()\n",
    "        trg_indices.append(pred_token)\n",
    "        \n",
    "        if pred_token == vocab.EOS_ID:\n",
    "            break\n",
    "    \n",
    "    # Decode\n",
    "    response = vocab.decode(trg_indices[1:-1])\n",
    "    return response\n",
    "\n",
    "\n",
    "# Test with some examples\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Example Inference\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "test_questions = [\n",
    "    \"안녕하세요\",\n",
    "    \"오늘 날씨가 좋네요\",\n",
    "    \"뭐 하고 있어요\",\n",
    "    \"고기 먹고 싶어\",\n",
    "    \"내가 좋아하는 거 알았는데도 나를 대하는게 변함이 없어.\",\n",
    "    \"내가 좋아하는 걸 티냈는데 그 사람은 반응이 없어.\"\n",
    "]\n",
    "\n",
    "for q in test_questions:\n",
    "    response = generate_response(model, q, vocab)\n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"A: {response}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "experiment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
